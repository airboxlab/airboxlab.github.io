<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airboxlab Technical Blog</title>
    <description>The guys behind Foobot.Talking here about our achievements, failures &amp; OSS contributions
</description>
    <link>https://airboxlab.github.io//</link>
    <atom:link href="https://airboxlab.github.io//feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 03 Mar 2022 15:38:44 +0100</pubDate>
    <lastBuildDate>Thu, 03 Mar 2022 15:38:44 +0100</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Autoregressive control policies for HVAC optimization</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
.double-left {
    width:49%;
    display:block;
    float:left;
    margin: 0 auto;
    margin-right: 10px;
}
.add-margin-right {
    margin-right: 20px;
}
.double {
    width: 49%;
    margin: 0 auto;
}
.double-unconst {
    width: auto;
    margin: 0 auto;
    margin-left: 1.5rem;
}
.image-foot {
    font-size:10pt;
    max-width: 30rem;
    margin: 0 auto;
}
.small-img {
  width: 45%;
}
ul {
  display: table;
}
&lt;/style&gt;

&lt;p&gt;This article deals with the use of autoregressive (AR) models in control policies. After a short background and litterature review, we formulate the problem statement and theoritical advantages over other control strategies involving taking multiple decisions at the same time.&lt;/p&gt;

&lt;p&gt;We then demonstrate it can overperform policies with ‚Äúclassic‚Äù models on a series of toy tasks (2D grid path-finding) and simulated Heating, Ventilation and Air Conditioning (HVAC) system environments.&lt;/p&gt;

&lt;h2 id=&quot;autoregressive-models-a-brief-introduction&quot;&gt;Autoregressive models: a brief introduction&lt;/h2&gt;

&lt;p&gt;Autoregressive (AR) models are commonly used in statistics and time series problems. They can be defined as regressions where outputs depend on previous values on the same time series. This indicates a strong &lt;em&gt;temporal&lt;/em&gt; dependency between past and future observations.
Famously known algorithms exist that build on this principle like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARMA&lt;/code&gt; (Autoregressive Moving Average) and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ARIMA&lt;/code&gt; (Autoregressive Integrated Moving Average).&lt;/p&gt;

&lt;p&gt;In the present article we‚Äôll give a slightly different meaning to &lt;em&gt;autoregressive&lt;/em&gt;, although the &lt;em&gt;temporal&lt;/em&gt; aspect is still there.&lt;/p&gt;

&lt;h3 id=&quot;multi-decisions-ar-models&quot;&gt;Multi-decisions AR models&lt;/h3&gt;

&lt;p&gt;In multi-decisions control problems, we often find the following methodology for solving optimization problems that involve applying multiple actions on an environment:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a single control policy is learnt that models multiple independent action probability distributions&lt;/li&gt;
  &lt;li&gt;multiple control policies model one action probability distribution each&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In real-world problems, there is often a dependency between multiple decisions taken in the same environment. Here are a few illustrations for control problems involving 2 decisions:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;a bipedal needs to coordinate his left and right legs&lt;/li&gt;
  &lt;li&gt;a car driver must coordinate actions on break and accelerator&lt;/li&gt;
  &lt;li&gt;‚Ä¶&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this type of problem, the dependency between actions is strong. That‚Äôs what AR models can help solving, by modeling a statistical dependency between an action and potentially many others.&lt;/p&gt;

&lt;p&gt;This differs from the broader definition of autoregressive models where the statistical dependency is between actions taken at different time steps: action is applied on the environment, result is observed, then a new action is decided that takes into account the previous action and its result on the environment.&lt;/p&gt;

&lt;p&gt;Below diagram illustrates these different ways of modeling decision processes with and without AR models&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/ar_def.svg&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 1: 3 ways of modeling decision processes with state / action transitions using independent actions distributions (a.) and AR models (b. and c.)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Note: nothing prevents from modeling both intra and inter-step dependencies.&lt;/p&gt;

&lt;h3 id=&quot;optimizing-multi-decisions-processes-with-reinforcement-learning&quot;&gt;Optimizing multi-decisions processes with Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;We‚Äôve briefly described different ways of modeling decision processes that aim at optimizing parameters of multiple actions probability distributions. Reinforcement learning (RL) is, in the family of machine learning / artificial intelligence techniques, a method that can be used to solve this. It is based on a trial-and-error learning process, where an agent tries to learn the optimal policy by interacting with its environment (actions), learning from observations (state) and rewards (also referred as penalties).&lt;/p&gt;

&lt;p&gt;Modeling methods described in previous section apply to RL as well, while independent action distributions are the modeling technique that is the most often used.&lt;/p&gt;

&lt;h4 id=&quot;independently-sampled-decisions&quot;&gt;Independently-sampled decisions&lt;/h4&gt;

&lt;p&gt;This is the most common case. In many classic problems, each action of a multi-decision problem is modeled and its probability distribution is estimated as independent from other actions. This doesn‚Äôt allow to account for relationships between actions that can be encountered in many problems.&lt;/p&gt;

&lt;h4 id=&quot;multi-agent&quot;&gt;Multi-agent&lt;/h4&gt;

&lt;p&gt;In a multi-agent setting, two or more agents are learning a policy by acting on the same environment. While there are problems with no collaboration needed between agents (each agent decisions has neutral impact on others), in this article we focus on relationships between decisions that have impact on the same shared state.
With this assumption, problem forumlation with multi-agent setup can lead to the well-known ‚Äúcredit assignment dilemma‚Äù: each agent needs to be rewarded for its action, but how can a fair credit be given to each since they influence the same system?&lt;/p&gt;

&lt;p&gt;Below diagram illustrates such a dilemma&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/ar_vs_ma.svg&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 2: 2 agents being rewarded on the same state, leading to a credit assignment problem&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Tricks and heuristics can be found to help with this issue but they can give suboptimal performance, when they exist at all.&lt;/p&gt;

&lt;h2 id=&quot;in-the-litterature&quot;&gt;In the litterature&lt;/h2&gt;

&lt;p&gt;An extensive review of all AR modeling techniques is out of the scope of this article. We focus on AR models in RL problems that aim at modeling dependencies between actions within the same control time step.&lt;/p&gt;

&lt;p&gt;In Harmer et al. (2018)&lt;a href=&quot;#1&quot;&gt;[1]&lt;/a&gt;, imitation learning is used in a 3D game setting that involves multiple actions. However, an assumption is made that actions are conditionnally independent given the state. This simplification reduces computational complexity, but doesn‚Äôt allow learning relationships between actions.&lt;/p&gt;

&lt;p&gt;In Wang et al. (2016)&lt;a href=&quot;#2&quot;&gt;[2]&lt;/a&gt;, an algorithm is proposed to introduce regularization terms in two classic RL methods. The regularization consists of 2 parameters that must be estimated alternatively on every learning step. This proves to improve learning performance on some classic control problems like 2D-grid navigation or Persistent Search and Track (PST).&lt;/p&gt;

&lt;p&gt;In Vinyals et al. (2017)&lt;a href=&quot;#3&quot;&gt;[3]&lt;/a&gt;, an extensive problem definition is given about training an agent on StarCraft II 3D-game. In particular, the action space representation is modeled to introduce conditional dependencies between action. (see section 4.2).&lt;/p&gt;

&lt;p&gt;Finally, in Germain et al. (2018)&lt;a href=&quot;#4&quot;&gt;[4]&lt;/a&gt;, a masked autoencoder neural network architecture is introduced to estimate parameters of probability distributions. The method uses masking so to respect autoregression constraint, which is to reconstruct an input only from previous inputs. This allows fast and scalable distributions estimation, with any type of ordering or relationship modeling constraints. The study doesn‚Äôt give any RL application example but it is theoritically usable for the policy network architecture.&lt;/p&gt;

&lt;h2 id=&quot;hvac-control-sequences-applications&quot;&gt;HVAC control sequences applications&lt;/h2&gt;

&lt;p&gt;HVAC systems are complex and made of multiple systems that interact in complex, non-linear ways (see a brief introduction on that in &lt;a href=&quot;https://airboxlab.github.io/hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html&quot;&gt;HVAC processes control: can AI help?&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;HVAC air loops are responsible for maintaining fresh air and good temperatures in buildings occupied zones. They can be seen as a sequence of decisions, starting from how much fresh air the systems lets in, going through deciding at what flow rate it must be pushed and at what temperature, and ending with how this air must be ‚Äúadjusted‚Äù for the target zone.
Many equipment are involved, like fans, heating and cooling coils, chilled and hot water plant loops, etc.&lt;/p&gt;

&lt;h3 id=&quot;why-is-it-a-good-fit&quot;&gt;Why is it a good fit?&lt;/h3&gt;

&lt;p&gt;Let‚Äôs build our intuition with an example: a heater is equipped with a hot water coil and a fan, and heats the space by controlling the hot water valve and the fan to blow the hot air. If you turn the fan off but keep valve open, hot air won‚Äôt move much, and energy consumption will be near 0. If you turn it to maximum position or speed, hot air will move quicker, room will heat quicker too, and energy consumption will be high, both because of the higher fan electricity consumption, and because it increases heat exchange between air and hot water coil.&lt;/p&gt;

&lt;p&gt;As a consequence, optimizing control on this simple heating system would require to consider both fan speed and hot water valve position, with prior knowledge that fan and valve have a non-linear dependency regarding temperature of the air blown and energy consumption.&lt;/p&gt;

&lt;p&gt;If we generalize this example, many parts of the HVAC system can be seen as dependent to or having a direct or indirect impact on other parts. Trying to control only one equipment as a whole will necessarily lead to suboptimal performance. However, this is often how HVAC systems are controlled: each equipment takes decision regarding a single input. No matter how complex the calculation of this input is, it won‚Äôt be differentiable since it‚Äôs a single scalar value. Common calculation methods for control decisions rely on linear methods (linear interpolations, PIDs, ‚Ä¶) with a narrow view of the state of the system.&lt;/p&gt;

&lt;p&gt;That‚Äôs where AR methods and Deep RL can be a good fit: combining function approximation capabilities of neural networks, theoritically unlimited observability of the system and modeling of actions dependencies, the HVAC system and the building it serves could be controlled as a whole (holistic approach), and learned policies could model complex relationships between states and equipment.&lt;/p&gt;

&lt;h3 id=&quot;formulation&quot;&gt;Formulation&lt;/h3&gt;

&lt;p&gt;Given a policy &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\pi_{\theta}&quot; /&gt; to optimize with regards to parameters &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\theta&quot; /&gt;, state &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=s \in \mathcal{S}&quot; /&gt;, a set of n actions &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=a_{i} \in \mathcal{A}&quot; /&gt;, we can represent the policy as following:&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\pi_{\theta}(a, s) = \prod_{i=1}^{n} \pi_{\theta}(a_{i} \bigm\lvert a_{k&amp;lt;i}, s)&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This simple formulation is generic and describes simple relationships and order with action at rank i being dependent on all previous actions.&lt;/p&gt;

&lt;p&gt;An example neural network architecture illustrating this formulation is given below&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/ar_nn_arch.svg&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 3: example neural network architecture to model conditional dependencies between actions&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;In this model, a policy with 2 actions is used. It should be noted that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 2&lt;/code&gt; are actually parameters of their respective probability distributions (PD).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 1&lt;/code&gt; scalar value (sampled from estimated PD) is passed as input for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 2&lt;/code&gt; distribution estimation&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 1&lt;/code&gt; &lt;em&gt;logits&lt;/em&gt; could be passed as input instead of scalar value. This can help preserve information on large discrete/categorical distributions.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 2&lt;/code&gt; inputs could be solely made of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Action 1&lt;/code&gt; output (scalar or logits). In such case policy can be formulated as &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\pi_{\theta}(a, s) = \pi_{\theta}(a_1, s) \cdot \prod_{i=2}^{n} \pi_{\theta}(a_{i} \bigm\lvert a_{k&amp;lt;i})&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that this model doesn‚Äôt use the masked autoencoder architecture, hence wouldn‚Äôt scale well for the estimation of a large number of actions distributions.&lt;/p&gt;

&lt;h2 id=&quot;experiments&quot;&gt;Experiments&lt;/h2&gt;

&lt;p&gt;To validate benefits of such architecture, we compare performance of ‚Äúclassic‚Äù network models with the one described in previous section. To draw a fair comparison, the same total number of neural network cells is used in classic and AR policies networks. Furthermore, all other parameters of the Proximal Policy Optimization (PPO, Shulman et al. &lt;a href=&quot;#5&quot;&gt;[5]&lt;/a&gt;) algorithm are kept equal between the 2 models.&lt;/p&gt;

&lt;h3 id=&quot;a-path-finding-task&quot;&gt;A path-finding task&lt;/h3&gt;

&lt;p&gt;The first task is a toy problem where an agent must navigate through a 2D-grid and maximize its reward by moving to certain locations. The action space is designed with 2 actions (vertical and horizontal movements). 
To emphasize on the need to learn correlation between actions, the reward scheme is modeled using 2 gaussian distributions located on 2 corners of the grid, and a one-time bonus whenever the agent reaches a point close to the mean of each gaussian. The agent start each episode starting at the center of the grid. Episode ends when all bonuses are found. We refer to this training environment as bi-modal environment (BME).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/bi_modal_env_grid.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 4: rewards distribution over the BME grid&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We run 5 experiments with different seeds for each method (classic and AR) on the BME and compare the mean return per episode below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/bi_modal_avg_return.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 5: average episode reward for non AR policy (classic, light green) and AR policy (dark green)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Visual inspection of trajectories for each method can highlight non-efficiencies and differencies. 
Below animations capture sample trajectories after 50 training iterations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/bi_modal_classic_traj.gif&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;
&lt;img src=&quot;/assets/ar_policy/bi_modal_ar_traj.gif&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 6a and 6b: average episode reward for classic policy (left) and AR policy (right)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;On this toy environment, AR policy achieves a much better mean episode reward than its counterpart.&lt;/p&gt;

&lt;h3 id=&quot;a-simulated-hvac&quot;&gt;A simulated HVAC&lt;/h3&gt;

&lt;p&gt;We now use a simulated building and its HVAC. The building model, or digital twin, is created from an actual building and calibrated on Foobot platform using OpenStudio and EnergyPlus opensource software. It is a 3 storey office building, with a dedicated outdoor air system, a single air handling unit (AHU) with eletric heating and chilled water coil served by a local plant, and fan coil units for zones comfort.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/dt_3d_geo.png&quot; alt=&quot;sources&quot; class=&quot;center small-img&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 7: office building used as a test environment&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A policy is trained with and without autoregressive (AR) actions model. The observation and action spaces, reward function, and PPO parameters are identical between the 2 methods. The action space is composed of 2 actions that command the amount and temperature of air supplied to the zones by the AHU. Each experiment is run for 1e6 timesteps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/hvac_env_rew.svg&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;
&lt;img src=&quot;/assets/ar_policy/hvac_env_power.svg&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;
&lt;br /&gt;
&lt;img src=&quot;/assets/ar_policy/hvac_env_tmp.svg&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;
&lt;img src=&quot;/assets/ar_policy/hvac_env_co2.svg&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 8: average episode reward (a., upper left), power demand (b., upper right, in kW), indoor temperature (c., lower left, in Celsius degrees) and CO2 (d., in ppm) for classic and AR policy (blue line) models&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;AR policy model not only achieves a better mean episode reward (fig 8a.), but it significantly outperforms (by 8.5%) the energy consumption reduction of the classic method. Other reward components, like thermal comfort and indoor air quality, are also better in line with their respective constraints which are a maximum of 25¬∞C indoor temperature and a maximum of 1000ppm for indoor CO2.&lt;/p&gt;

&lt;h3 id=&quot;analysing-impacts-and-relationships&quot;&gt;Analysing impacts and relationships&lt;/h3&gt;

&lt;p&gt;To understand better our model, a short study is conducted to highlight how action 1 influence action 2, how each action influence the state space, and what part of the state space has the most influence on agent decisions.&lt;/p&gt;

&lt;p&gt;To do that, we‚Äôll first map our system and learned policy with functions approximations that govern it:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;transitions&lt;/em&gt; that associates an action and a state to a next state &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=f_{tr}(a_{t}, s_{t}) \Rightarrow s_{t'}&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;rewards&lt;/em&gt; that maps action and state with its immediate reward &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=f_{rew}(a_{t}, s_{t'}) \Rightarrow r_{t}&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;policy&lt;/em&gt; that maps a state and the next action &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=f_{p}(s_{t}) \Rightarrow a_{t'}&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;autoregression&lt;/em&gt; that looks for correlation between action 1 and action 2 &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=f_{ar}(a_{1, t}) \Rightarrow a_{2, t}&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We then compute the jacobian of each function in order to differentiate with respect to relevant parameters. For instance, to highlight what part of the state space is directly influenced by agent decisions, we‚Äôll use the jacobian of the transitions function &lt;img src=&quot;https://render.githubusercontent.com/render/math?math=\mathbb{J}({f_{tr}})&quot; /&gt; and differentiate with respect to agent actions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/jac_f_p1.png&quot; alt=&quot;sources&quot; class=&quot;double-unconst&quot; /&gt;
&lt;img src=&quot;/assets/ar_policy/jac_f_p2.png&quot; alt=&quot;sources&quot; class=&quot;double-unconst&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 9: what part of the state space influences decisions the most, for each action a1 (left) and a2 (right). Actions a1 and a2 seem influenced by different parts of the state&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/jac_f_tr.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 10: what part of the state space is &quot;controllable&quot; by the policy, for each action (a1, a2) of the space. Here indoor conditions are the most influenced, from both actions&lt;/i&gt;&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ar_policy/jac_f_ar.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center class=&quot;image-foot&quot;&gt;&lt;i&gt;fig. 11: what values of a1 influence the most decisions on a2. This highlights potential non-linear relationships between certain parts of the a1 action space and a2&lt;/i&gt;&lt;/center&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Through a series of examples we‚Äôve demonstrated that autoregressive (AR) policies can bring significant performance and training speed improvements compared to more classic models.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a id=&quot;1&quot;&gt;[1]&lt;/a&gt; 
Jack Harmer, Linus Gissl√©n, Jorge del Val, Henrik Holst, Joakim Bergdahl, Tom Olsson, Kristoffer Sj√∂√∂, Magnus Nordin. 
&lt;i&gt;Imitation Learning with Concurrent Actions in 3D Games.&lt;/i&gt; &lt;a href=&quot;https://arxiv.org/abs/1803.05402&quot;&gt;2018&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&quot;2&quot;&gt;[2]&lt;/a&gt;
Han Wang and Yang Yu.
&lt;i&gt;Exploring Multi-Action Relationship in Reinforcement Learning.&lt;/i&gt; &lt;a href=&quot;http://www.lamda.nju.edu.cn/wanghan/pricai16.pdf&quot;&gt;2016&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&quot;3&quot;&gt;[3]&lt;/a&gt;
Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K√ºttler, John Agapiou, Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen, Karen Simonyan, Tom Schaul, Hado van Hasselt, David Silver, Timothy Lillicrap, Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence, Anders Ekermo, Jacob Repp, Rodney Tsing.
&lt;i&gt;StarCraft II: A New Challenge for Reinforcement Learning.&lt;/i&gt; &lt;a href=&quot;https://arxiv.org/abs/1708.04782&quot;&gt;2017&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&quot;4&quot;&gt;[4]&lt;/a&gt;
Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle.
&lt;i&gt;MADE: Masked Autoencoder for Distribution Estimation&lt;/i&gt; &lt;a href=&quot;https://arxiv.org/abs/1502.03509&quot;&gt;2015&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a id=&quot;5&quot;&gt;[5]&lt;/a&gt;
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov.
&lt;i&gt;Proximal Policy Optimization Algorithms&lt;/i&gt; &lt;a href=&quot;https://arxiv.org/abs/1707.06347&quot;&gt;2017&lt;/a&gt;&lt;/p&gt;

</description>
        <pubDate>Wed, 23 Feb 2022 01:00:00 +0100</pubDate>
        <link>https://airboxlab.github.io//hvac/rl/autoregressive/2022/02/23/ar_policy.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//hvac/rl/autoregressive/2022/02/23/ar_policy.html</guid>
        
        
        <category>hvac</category>
        
        <category>rl</category>
        
        <category>autoregressive</category>
        
      </item>
    
      <item>
        <title>Crowd sourced classifier to identify air pollution sources</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
&lt;/style&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Foobot designs and manufactures indoor air quality monitors since 2013. These monitors are connected to a cloud platform that collects and process sensor readings from around the world; customers can visualize their data from mobile or web interfaces. Foobots have been used in homes, offices and research context.&lt;/p&gt;

&lt;p&gt;As a sensor device manufacturer, our goal isn‚Äôt only to provide a &lt;em&gt;thermometer&lt;/em&gt; for air quality, the end goal is to reduce exposure to air pollution for our customers. For that we have been involved in the engineering of several air purifier lines over the years. We also perceived that it is key for users to understand what actions lead to poorer air indoor. When one understands where pollution comes from, (s)he can perform remediation actions, or set an automated way to deal with it.&lt;/p&gt;

&lt;h2 id=&quot;identify-pollution-sources&quot;&gt;Identify pollution sources&lt;/h2&gt;

&lt;p&gt;Air quality is complex, and it is always challenging to identify a root cause when air pollution rises. It can be due to outdoor events, like wildfires or traffic pollution, but often, the pollution source is indoor. Within dwellings, there are a number of air quality events triggered by inhabitants. Our actions and behaviors indoor impact the air quality we live in; for the better, when we switch on the cooking hood, or for the worth when we are cleaning the bathroom with harsh chemicals.&lt;/p&gt;

&lt;p&gt;Foobot home sensors measures four environmental parameters: fine particulates (PM), volatile organic compounds (VOC), temperature and relative humidity. The challenge in creating a feature that can show user a root cause for a pollution event is to identify a unsique &lt;em&gt;signature&lt;/em&gt; over these 4 environmental parameters measured.&lt;/p&gt;

&lt;p&gt;This article describes the process we followed to collect a dataset and to setup an automated air quality event classifier.&lt;/p&gt;

&lt;h3 id=&quot;crowd-collected-dataset&quot;&gt;Crowd collected dataset&lt;/h3&gt;

&lt;p&gt;We created a feature for our users to label their data. It allowed enrolled users to receive a push notification each time an air quality event was detected. The push notification opens up Foobot mobile app where users were able to choose the action that was carried on, or to enter free text.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/iphone_classify.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Push notification for classification&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The detection of an event, meaning the kind sensor deviation that constitute it, and the timing to trigger a push notification to a user is a topic on its own. It took us several iterations to maximize the number of responses and to avoid bothering users for non-event, or for events that happened too long ago and that they couldn‚Äôt to identify anymore.&lt;/p&gt;

&lt;p&gt;Thanks to this feature and the users enrolled we were able to collects tens of thousands of labeled events.&lt;/p&gt;

&lt;h2 id=&quot;data-analysis&quot;&gt;Data analysis&lt;/h2&gt;

&lt;p&gt;Now let‚Äôs introduce some basic techniques for data segmentation and classification we used to visualize labeled &lt;em&gt;air quality events&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;dataset-description&quot;&gt;Dataset description&lt;/h3&gt;

&lt;p&gt;The dataset that is used for the purpose of this article is a subset of Foobot full dataset. It contains &lt;em&gt;extracted features&lt;/em&gt; from sensor data time series and other continuous and categorical features, as well as associated tags given by users. These labels will be, used as classes to train a classifier. Selected samples are from devices and users located in the US and Europe.&lt;/p&gt;

&lt;p&gt;For the sake of simplicity and readability we‚Äôll only detail 3 specific labels, though we have proven our method to work with quite a few others:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Cooking&lt;/em&gt;&lt;/strong&gt; consequence of a cooking action. This is one of the most common source of indoor air pollution. It is quite challenging to detect accurately because of the variety of event types it amalgamates. eg: frying, oven cooking, steaming.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Air renewal&lt;/em&gt;&lt;/strong&gt; opening a door, a window, switching ON some kind of ventilation. It appeared important to be able to detect remediation events. Either to reward users or to just to be able to prevent an automated system from asking users to perform an action already performed. We could also derive an airing score out of this metric.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Presence&lt;/em&gt;&lt;/strong&gt; people coming and going in the space. Whether someone is around or not is important for an automated system to decides what to communicate to an end user. It was also an interesting challenge since the Foobot home sensor doesn‚Äôt feature a CO2 sensor.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;tools&quot;&gt;Tools&lt;/h3&gt;

&lt;p&gt;This short analysis uses &lt;a href=&quot;https://spark.apache.org&quot;&gt;Spark&lt;/a&gt; (mostly for data extraction) as well as &lt;a href=&quot;http://scikit-learn.org/&quot;&gt;scikit-learn&lt;/a&gt;. Visualizations are performed with &lt;a href=&quot;https://matplotlib.org/&quot;&gt;matplotlib&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;overview&quot;&gt;Overview&lt;/h3&gt;

&lt;p&gt;Intuitively, air quality events will have different ‚Äúsignatures‚Äù, that is they will be expressed differently in data. For instance, cooking could be a source of particulate matters, while air renewal can translate into change in temperature, humidity and/or volatile organic compounds (VOC). These are just a few examples to build our intuition, there are many others.&lt;/p&gt;

&lt;p&gt;To get a first feeling of how they show up in data, let‚Äôs see how &lt;em&gt;difference between maximum and minimum value around event time&lt;/em&gt;* is characterized&lt;/p&gt;

&lt;div style=&quot;font-size:12px;margin-bottom:15px&quot;&gt;*feature extraction in time windows isn't detailed in this article&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/pm_diff_max_min_box.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Boxplot of difference between PM max and min values, by tag&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A first interpretation of this &lt;a href=&quot;https://en.wikipedia.org/wiki/Box_plot&quot;&gt;box plot&lt;/a&gt; is that cooking is statistically the event that makes PM readings vary the most: difference in 25%-75% range is wider than for other events, and maximum is much higher. See also the shape of the plot for air renewal, showing that variance is also important: could be due to PM being cleared or moved by airflow.&lt;/p&gt;

&lt;p&gt;Let‚Äôs see some other plots for VOCs and humidity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/voc_diff_max_min_box.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Boxplot of difference between VOC max and min values, by tag&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/hum_diff_max_min_box.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Boxplot of difference between humidity max and min values, by tag&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This time, we can see that VOC and humidity levels seem to be impacted the most by air renewal (first) and then presence.&lt;/p&gt;

&lt;p&gt;We now have an intuition about how air quality changes affects some of Foobot‚Äôs sensors readings. We can go a bit further by checking how variance in data distinguish event types.&lt;/p&gt;

&lt;h3 id=&quot;using-variance-in-data-with-principal-components-analysis&quot;&gt;Using variance in data with Principal Components Analysis&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Principal_component_analysis&quot;&gt;Principal Components Analysis (PCA)&lt;/a&gt; is a common technique mostly used for&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dimensionality reduction: if variance in data can be explained by few &lt;em&gt;principal components&lt;/em&gt; (where number of principal components &amp;lt; number of features) then one can use these components for further analysis, mining or model training&lt;/li&gt;
  &lt;li&gt;visualization: 2 or 3 principal components are easy to plot, so PCA is convenient to visualize how variance is explained in data, especially when associating labels with data points.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PCA also has its limits: it really works well when problem is linear, that is when data you want to split is linearly separable. Let‚Äôs not forget also that PCA just provides a rotation (or projection onto a different space) which maximizes the variance (principle: diagonalization of the covariance/correlation matrix) for the given data, using fewer dimensions. It can‚Äôt go beyond; it‚Äôs not a classifier.&lt;/p&gt;

&lt;p&gt;Using PySpark and scikit-learn, it‚Äôs a straightforward task to setup a toy pipeline that pre-processes our dataset (like standardizing features), then applies PCA.
Following plots are demonstrating PCA with 2 and 3 components.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/pca_k_2.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;PCA of air quality events (k=2)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/pca_k_3.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;PCA of air quality events (k=3)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Here we achieve a visualization that projects all the features of our dataset onto the PCA features space (2 or 3 dimensions). We can see a trend in groups of points that seem to belong to each label. However, a simple interpretation can state that linear separability across tags isn‚Äôt achieved: although data belonging to air renewal and cooking groups seem to segregate from each other well, presence (&lt;em&gt;many people&lt;/em&gt;) has data points mixed up with the 2 previous classes. A simple intuition could explain this: presence could be true at the samae time than the other classes.&lt;/p&gt;

&lt;h3 id=&quot;going-non-linear-with-polynomial-expansion&quot;&gt;Going non-linear with Polynomial Expansion&lt;/h3&gt;

&lt;p&gt;Since we weren‚Äôt able to linearly separate data in a clear way, let‚Äôs try a non-linear method to see if we can better manage this. A first option is &lt;a href=&quot;https://en.wikipedia.org/wiki/Polynomial_expansion&quot;&gt;polynomial expansion&lt;/a&gt; (a particular method of basis expansion) which consists in projecting data onto a different space, here formed by polynomial combinations of all existing features. For instance, if you have features &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[a b]&lt;/code&gt;, a 2nd degree expansion would result in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[ a b ab a¬≤ b¬≤]&lt;/code&gt;. We can then use the result as an input for a linear transformer or classifier, which is good also to preserve the low complexity of a linear algorithm to make projections or decisions in a non-linear space.&lt;/p&gt;

&lt;p&gt;Though you can guess it: it will require huge computational power if polynomial degree is high, and number of features is large. Also, the higher the degree, the more models using this new feature space will tend to overfit.&lt;/p&gt;

&lt;p&gt;For the purpose of this article, we‚Äôll only try 2nd degree polynomial.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/pca_pe_k_2.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Polynomial expansion &amp;amp; PCA (k=2)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/pca_pe_k_3.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Polynomial expansion &amp;amp; PCA (k=3)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A clear change in projection, and a (visually) better separation of cooking and air renewal data. Presence (many people) is still not properly separated.&lt;/p&gt;

&lt;h3 id=&quot;going-non-linear-with-kernel-pca&quot;&gt;Going non-linear with Kernel PCA&lt;/h3&gt;

&lt;p&gt;Another method uses the &lt;a href=&quot;https://en.wikipedia.org/wiki/Kernel_method&quot;&gt;kernel trick&lt;/a&gt; applied to PCA. It‚Äôs basically also a change of space, as it projects data onto a higher dimensional space. A &lt;em&gt;kernel&lt;/em&gt; function is applied to each sample before PCA is applied.&lt;/p&gt;

&lt;p&gt;Multiple ‚Äústandard‚Äù kernel functions exist (like &lt;em&gt;gaussian radial basis function&lt;/em&gt; (RBF)). Choosing the right one is a difficult task when it‚Äôs meant to be used in a model training pipeline. Here we‚Äôre using the &lt;em&gt;cosine&lt;/em&gt; kernel function, only because it offers good visualization results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/kpca_k_2.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Kernel PCA (k=2)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/kpca_k_3.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Kernel PCA (k=3)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Again, separation between cooking and air renewal data is good. This time ‚Äòpresence‚Äô (many people) seems to overlap with cooking only, which makes sense: people are usually in the room where they cook.&lt;/p&gt;

&lt;h3 id=&quot;a-supervised-learning-technique-linear-discriminant-analysis&quot;&gt;A supervised learning technique: Linear Discriminant Analysis&lt;/h3&gt;

&lt;p&gt;We didn‚Äôt manage to separate data between classes well with PCA in the previous section. In order to go further, we‚Äôre now going to use a supervised learning technique that takes into account classes (tags). Actually, it‚Äôs a well known classifier that has several advantages: efficient computing, no hyper parameter tuning, and possibility to reduce dimensionality.&lt;/p&gt;

&lt;p&gt;This is what &lt;a href=&quot;https://en.wikipedia.org/wiki/Linear_discriminant_analysis&quot;&gt;Linear Discriminant Analysis&lt;/a&gt; is capable of. Like PCA, it‚Äôs a linear transformation, and the goal is to find a projection that maximizes variance, but this time between classes. It runs well under the assumptions that class densities are Gaussian and that each class covariance matrix is similar, assumptions that are not often met in real world problems.&lt;/p&gt;

&lt;p&gt;We‚Äôre going to use it here only for its dimensionality reduction capability, and we‚Äôll project our data onto a subspace made only of the number of dimensions we‚Äôre interested in: LDA lets us choose number of components &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt;, but it can only be such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k &amp;lt; n-1&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; = number of classes).&lt;/p&gt;

&lt;p&gt;LDA remains a linear method (linear decision boundaries) and tends to overfit the data as number of features (dimensions) grows.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/lda_k_2.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;LDA (k=2)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/lda_k_3.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;LDA (k=3)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This time, even if it‚Äôs not a strict visual separation of data, classes seem to form distinct groups.&lt;/p&gt;

&lt;h3 id=&quot;non-linear-lda&quot;&gt;Non-linear LDA&lt;/h3&gt;

&lt;p&gt;In order to obtain quadratic (no more linear) decision boundaries and improve our classification, we‚Äôre now going to project our data onto a higher dimensional space formed by using polynomial expansion before fitting LDA.&lt;/p&gt;

&lt;p&gt;It‚Äôs also worth noting that &lt;em&gt;Quadratic Discriminant Analysis&lt;/em&gt; exists, and in practice gives very similar results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/qlda_k_2.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Polynomial LDA (k=2)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/qlda_k_3.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Polynomial LDA (k=3)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This time, a clear separation is obtained.&lt;/p&gt;

&lt;h2 id=&quot;accuracy-verification&quot;&gt;Accuracy verification&lt;/h2&gt;

&lt;p&gt;As we discovered, distinguishing or classifying air quality events classes is a non-trivial task. Pure linear methods do not give good results and we have to use the technique of basis expansion (polynomials) along with LDA in order to get a proper classification. Although results were promising to build a classifier, we also have to consider:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Users live in different indoor and outdoor conditions: from one region of the world to another, habits are different, outdoor air quality is different, temperature and humidity vary greatly.&lt;/li&gt;
  &lt;li&gt;Air quality events are difficult to track by nature: there can be several happening at the same time, there can be a delay between start of event and impact on sensor readings, same type of event will have a different expression from one place to another (e.g. air renewal in a polluted city vs countryside).&lt;/li&gt;
  &lt;li&gt;Generalization capability of the classifier, which should be verified with (cross-)validation and testing.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All these possible hurdles called for a verification to evaluate the performance of our classifier.&lt;/p&gt;

&lt;h3 id=&quot;crowd-sourced-classification-check&quot;&gt;Crowd sourced classification check&lt;/h3&gt;

&lt;p&gt;In the same way that we uses a subset of our users to help build a labeled dataset we proposed them to verify the accuracy of our classifier. We introduced a new feature that is, this time, not asking the user to label an event, but rather to check if the label to assigned to an event is correct:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/viz_aqe/iphone_valid.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Event validation push notification&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;With user being able to enter sub-categories or reclassify wrongly labeled events, we were able to iterate and improve. Today our accuracy in detecting the different events are the following for the main ones:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Cooking&lt;/strong&gt; 88%&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Air renewal&lt;/strong&gt; 98%&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Presence&lt;/strong&gt; 96%&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cleaning&lt;/strong&gt; 100%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Worth to be noticed is that we are able to label these events in a streaming fashion, meaning that data points are classified live while they are being collected thanks to Spark streaming.&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Jul 2021 02:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//data_science/air_quality/classifier/machine_learning/2021/07/01/events-class.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//data_science/air_quality/classifier/machine_learning/2021/07/01/events-class.html</guid>
        
        
        <category>data_science</category>
        
        <category>air_quality</category>
        
        <category>classifier</category>
        
        <category>machine_learning</category>
        
      </item>
    
      <item>
        <title>Nine months of AI-based control optimization on a modern office building HVAC</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
.double-left {
    width:49%;
    display:block;
    float:left;
    margin: 0 auto;
    margin-right: 10px;
}
.add-margin-right {
    margin-right: 20px;
}
.double {
    width:49%;
    margin: 0 auto;
}
.image-foot {
    font-size:10pt;
}
ul {
  display: table;
}
&lt;/style&gt;

&lt;h2 id=&quot;foobot-smart-air-building-sab-project&quot;&gt;Foobot Smart Air Building (SAB) project&lt;/h2&gt;

&lt;p&gt;In October 2020, SAB artificial intelligent agents took control over a 15000 m¬≤ commercial building HVAC system. This building, located in Northern Europe, was a real challenge:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a recent (2015), awarded construction. It obtained the &lt;i&gt;DGNB Platinum&lt;/i&gt; construction certification.&lt;/li&gt;
  &lt;li&gt;a modern building management system (BMS), with fancy, state-of-the-art control sequences&lt;/li&gt;
  &lt;li&gt;a low energy consumption baseload for the HVAC system: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;32 kWh/m¬≤¬∑year&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Within a few weeks, we rolled out the SAB HVAC optimization workflow:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;building characteristics and energy &lt;b&gt;data collection&lt;/b&gt;, along with facility managers interview to get a better understanding of known pain points&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;digital twin acquisition&lt;/b&gt;, by crafting a building model calibrated against actual building energy data&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;smart agents training&lt;/b&gt;, by using the digital twin as safe, accurate training environment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This method allowed us, within a short time frame, to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;present several optimization strategies, backed by solid energy savings estimates&lt;/li&gt;
  &lt;li&gt;discuss and validate the best strategies&lt;/li&gt;
  &lt;li&gt;design and apply a tailor-made test plan&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After test plan was fully executed and initial results in line with expectations, our customer gave us the green light for 24/7 control.&lt;/p&gt;

&lt;h2 id=&quot;day-1---a-good-slash&quot;&gt;Day 1 - a good slash&lt;/h2&gt;

&lt;p&gt;Our smart agents‚Äô performance is monitored using opensource tools like Grafana, and aggregated performance Key Performance Indicators (KPI) are continuously computed to track savings, comfort and AQI over the course of several months and years.&lt;/p&gt;

&lt;p&gt;In early October 2020, we gave our agents the go-live and watchedüçø&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/sab_after_9_months/day_1.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 1: SAB AI agents performance comparison over a 4 days period (source: Grafana dashboard)&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This 7th of October 2020, there was a drastic cut in HVAC energy consumption. All HVAC energy uses (AHU electricity and per-floor heating, showed with different colors in stacked bars chart) were significantly reduced despite similar weather conditions compared to previous, non-SAB days.&lt;/p&gt;

&lt;p&gt;What it demonstrated:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;HVAC was running at design conditions all the time. Air flow rate was too high for building heating and air renewal needs&lt;/li&gt;
  &lt;li&gt;there was too much reheat at floor level. Supplied air temperature was too cold, leading to waste of heating at each floor&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;after-9-months&quot;&gt;After 9 months&lt;/h2&gt;

&lt;p&gt;The first few days went good. But this isn‚Äôt enough to demonstrate efficiency of a solution. You need, ‚Ä¶ time.&lt;/p&gt;

&lt;p&gt;Today, we release some key metrics that show how SAB agents did their job. Starting with the classic Energy v.s. Heating Degree Day scatter and linear regression.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/sab_after_9_months/e_hdd_fit.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 2: Energy / Heating Degree Day fit&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;From this first chart, we see SAB is overperforming in every situation, mild or cold weather. The regression slope is steeper for the BMS as HDD increases; it can be interpreted as the HVAC sensitivity to weather, and SAB agents are much less sensitive than the BMS.&lt;/p&gt;

&lt;p&gt;To get a better understanding on each method performance, we can use a piecewise regression (a.k.a segmented regression) to identify some patterns&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/sab_after_9_months/e_w_fit.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 3: Piecewise energy / weather fit&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This time, x axis uses daily mean outdoor temperature. What we observe:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Energy Use Intensity is confirmed smaller&lt;/li&gt;
  &lt;li&gt;heating change point is close to same between BMS and SAB control, at about 10¬∞C. This means that heating needs to kick in only when outdoor temperature is 10¬∞C or below.&lt;/li&gt;
  &lt;li&gt;baseload (horizontal part of the regression) is also improved with SAB: HVAC system, under optimal weather conditions, runs with less&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h2&gt;

&lt;p&gt;The figure: &lt;b&gt;a 54% cut in HVAC spending, with no compromise on thermal comfort or indoor air quality&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;What we learned:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;every building is different, and every tenant has his/her own settings and preferences. You can advise to change set points and tell people to wear a sweater, or you can use a smart system. In present case, thermostat set points weren‚Äôt changed and are respected 98% of the time. Air quality is near perfect, with measured CO2 below 900ppm 100% of the time.&lt;/li&gt;
  &lt;li&gt;a successful project requires solid foundations: by giving precise estimates and several optimisation choices to our customers, expectations are set. In present case, actual savings show a 5-10% error with estimates (for winter months, savings were estimated at 50%)&lt;/li&gt;
  &lt;li&gt;visibility is key: we built an alerting and monitoring system that we and our customers use every day. It goes from standard HVAC health checks (like prescribed by ASHRAE guideline 36 for VAV systems) to tailor-made alerts, with auto-remediation, and real-time monitoring. All building sensors data, as well as KPIs, are visible to everyone involved in the project&lt;/li&gt;
  &lt;li&gt;reactivity and security are not optional: if something goes wrong, you need to know it immediately and react as fast as possible. This leads to automating everything. As a consequence, all our control loops deployment pipelines are fully automated, isolated and secured.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 21 Jun 2021 02:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//hvac/control/ai/reinforcement_learning/2021/06/21/sab_after_9.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//hvac/control/ai/reinforcement_learning/2021/06/21/sab_after_9.html</guid>
        
        
        <category>hvac</category>
        
        <category>control</category>
        
        <category>ai</category>
        
        <category>reinforcement_learning</category>
        
      </item>
    
      <item>
        <title>HVAC processes control: can AI help?</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
.double-left {
    width:49%;
    display:block;
    float:left;
    margin: 0 auto;
    margin-right: 10px;
}
.add-margin-right {
    margin-right: 20px;
}
.double {
    width:49%;
    margin: 0 auto;
}
.image-foot {
    font-size:10pt;
}
ul {
  display: table;
}
&lt;/style&gt;

&lt;p&gt;Through a series of examples, this article deals with limitations of classic controllers and control strategies in 
&lt;em&gt;Heating, Ventilation and Air Conditioning&lt;/em&gt; (HVAC) systems, and draws a comparison with &lt;em&gt;intelligent agents&lt;/em&gt; (supported
by artificial intelligence techniques) and their benefits. As such, we take as a basis of comparison a common HVAC
system type (&lt;em&gt;Variable Air Volume&lt;/em&gt; or VAV) and show where classic control technics fall short while intelligent agents
bring in better performance.&lt;/p&gt;

&lt;h2 id=&quot;hvac-components-control-optimization-context&quot;&gt;HVAC components control optimization: context&lt;/h2&gt;

&lt;p&gt;According to &lt;a href=&quot;https://www.eia.gov/consumption/commercial/reports/2012/energyusage/&quot;&gt;US Energy Information Agency&lt;/a&gt;, HVAC
systems were responsible for not less than 40% of energy consumption in commercial buildings in 2012. With such a 
significant footprint, everyone has an interest in optimizing their control and operations.&lt;/p&gt;

&lt;p&gt;Below diagram gives a simplified description of such HVAC system, of &lt;em&gt;VAV&lt;/em&gt; type, as we find in many buildings in US,
Europe and Asia since 1980 onwards. This type of system, as its name suggests, varies the amount of air to meet heating,
cooling and air renewal demands in building spaces. While its installation cost is higher than previous generation 
(namely, &lt;em&gt;Constant Air Volume&lt;/em&gt;), it has replaced it advantageously since it brings better comfort guarantees and less
energy expenses. We encounter this in medium to large size buildings mainly, in every kind of facilities.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/ncc_hvac_schematics.svg&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 1: simplified schematics of a typical Variable Air Volume (VAV) HVAC system, with central mechanical cooling and hot water reheat&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;As we can observe, a VAV is a centralized system: most of the ventilation, cooling and heating happens in one place, and
this requires to be configured and operated to meet all demands. By intuition, one can already imagine the challenges
that such systems face: a single (or a handful of) equipment of any kind must satisfy potentially dozens of open spaces,
cell offices, meeting rooms, ‚Ä¶ This requires proper sizing, configuration and control.&lt;/p&gt;

&lt;p&gt;To do so, HVAC industry relies on processes, hardware and techniques that, for some of them, are decades-old. Given
investment costs to design and promote new equipment or control techniques, but also to replace those already installed,
there is some inertia, legitimate to some extent. But as we‚Äôll discuss in next sections, optimisation or removal of
existing limitations don‚Äôt require many capital expenditure anymore. Modern, software-based approaches can
bring dramatic improvements without a full-fledged retrofit.&lt;/p&gt;

&lt;h2 id=&quot;shortcomings-of-classic-controllers-in-hvac-systems&quot;&gt;Shortcomings of classic controllers in HVAC systems&lt;/h2&gt;

&lt;p&gt;To understand what can go wrong, let‚Äôs begin our short study by describing classic control systems and strategies in
HVAC systems, backed by concrete examples of sub-optimal control in an actual building.&lt;/p&gt;

&lt;h3 id=&quot;a-classic-controller-case-study-proportional-integral-derivative&quot;&gt;A classic controller case study: Proportional-Integral-Derivative&lt;/h3&gt;

&lt;p&gt;Proportional-Integral-Derivative, or &lt;em&gt;PID&lt;/em&gt;, are the three calculation terms employed in this type of controller to
obtain a process control loop. For many decades, it‚Äôs the go-to in industrial processes, and HVAC systems are no
exception.&lt;/p&gt;

&lt;p&gt;However, they have known limitations, that are common to all PID controllers or more specific to HVAC-related processes.
Below we summarize some of them, in order to build a first intuition on what could be optimized.&lt;/p&gt;

&lt;h4 id=&quot;typical-limitations-of-a-pid&quot;&gt;Typical limitations of a PID&lt;/h4&gt;

&lt;p&gt;Let‚Äôs take an example with an actual PID controller used to vary supply air fan speed in a VAV system. A common control
strategy is to make the most-open VAV box damper position reach 90%. So this PID has the maximum of all dampers position
as input, a fixed set point of 90%, and outputs fan speed.&lt;/p&gt;

&lt;p&gt;The first limitation is intrinsically coming from how PID works: it requires a margin in the set point to produce stable
results when the controlled process is mechanical (e.g. fan speed can‚Äôt go higher than 100% or lower than 0%). When the 
limit of process range is reached, errors accumulate but the controlled process can‚Äôt go further in the same direction. 
This is known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Integral_windup&quot;&gt;integral windup&lt;/a&gt;. When it comes to fan control, a 
typical strategy is then to fix the set point below range limit, usually 90%.&lt;/p&gt;

&lt;p&gt;The second limitation is also inherent to PID internals: a large change in set point or in input value will produce
excessive change in the output (mostly due to derivative part of the PID: on a large change, derivative term will be
very large). A common solution is to use ramping either on set point or on PID input (in some ‚Äúenhanced‚Äù controllers).
This produces very slow responses, on a fan start-up that means a long delay before reaching the set point. This can be
observed on below chart, where it takes more than 30min for the PID to reach the set point.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/pid_fan_rampup.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 2: supply fan speed controlled by a PID and most-open VAV damper position (used as PID input) show a slow 
ramp-up of about 30min&lt;/i&gt;&lt;/center&gt;

&lt;p&gt;Note: ramping is still necessary to deal with mechanical constraints, a common rule is to avoid changes larger than 10%
per minute on fan speed.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;A third limitation comes from &lt;a href=&quot;https://en.wikipedia.org/wiki/PID_controller#Loop_tuning&quot;&gt;PID gains tuning&lt;/a&gt; which is a
tedious and time-consuming process. Even when controllers come with pre-defined and safe tunings for a particular class
of equipment, the HVAC engineer will have to reconfigure them to reach good performance, since each ventilation system
is unique. However, this tuning, performed once for all (HVAC configurations are only partially revised from time to
time), has about zero chance to cover all operating conditions. This results in typical PID problems like &lt;em&gt;overshooting&lt;/em&gt;
,
&lt;em&gt;oscillations&lt;/em&gt; or &lt;em&gt;hunting&lt;/em&gt;. This can be observed in chart below, where the desired set point is still fixed at 90%&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/pid_fan_oscillations.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 3: supply fan speed controlled by a PID subject to large oscillations&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Last but not least, PID controllers are often driven by a single input: in our case, most-open VAV damper position.
However, is this really the goal of a supply fan or did we just find a proxy to accommodate with controller
specifications? The actual real goal is to maintain good thermal and air quality comfort in occupied spaces, while
minimizing energy consumption.&lt;/p&gt;

&lt;p&gt;While the proxy target of 90% can satisfy first part, it has no consideration for energy
savings. How does this translate? This is very usual to find one damper open at 90% while others are way below. This isn‚Äôt
just a PID problem (or more specifically, just with the PID controlling the fan), but it‚Äôs natural to have zones with
less air demand than others, and zones that are almost always in demand (also known as rogue zones). With a PID, one
can‚Äôt do anything about that. Figure 4 illustrates this problem, where a large difference occurs between damper
positions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/pid_dampers_position.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 4: supply fan control strategy leading to large differences between VAV boxes dampers position&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;if-only-i-had-known-that-before&quot;&gt;‚ÄúIf only I had known that before‚Ä¶‚Äù&lt;/h4&gt;

&lt;p&gt;A PID is only reacting: for a given change in input, it will vary its output to keep as close as possible to its set
point. It has no way to anticipate changes or take proactive actions, since it has neither explicit nor inferred knowledge of
the controlled system. Moreover, its single input gives it a very partial view of the process at hand.&lt;/p&gt;

&lt;p&gt;With such &lt;em&gt;observer model&lt;/em&gt;, anticipation isn‚Äôt possible, while simple intuitions could be used to save bits of energy
here and there. A simple example: when HVAC scheduled end of operations is in sight, one could be tempted to slowly
reduce heating or cooling equipment use but not too much to reach end time between desired spaces set points. This is
something a PID can‚Äôt do.&lt;/p&gt;

&lt;p&gt;If we generalise this example, &lt;strong&gt;the optimal system should learn building thermal dynamics and discover best control
strategies&lt;/strong&gt;. There are many, and they depend on building use and characteristics.&lt;/p&gt;

&lt;h3 id=&quot;design-conditions-versus-reality&quot;&gt;Design conditions versus reality&lt;/h3&gt;

&lt;p&gt;As stated in &lt;em&gt;Pacific Northwest National Laboratory&lt;/em&gt;
report &lt;a href=&quot;https://www.pnnl.gov/main/publications/external/technical_reports/pnnl-22072.pdf&quot;&gt;Energy Savings for Occupancy-Based Control (OBC) of Variable-Air-Volume (VAV) Systems&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Each terminal box has a minimum air-flow rate that ensures the ventilation requirements of the occupants of the zone served are met. This minimum air-flow rate is maintained at a constant value based on the design occupancy of the zone, which often corresponds to the maximum occupancy, because measurements of actual occupancy are not currently used to adjust the flow rate. [‚Ä¶] In practice, control system integrators and installers often set the cooling minimum air-flow rate for ventilation to between 30% and 50% of the maximum air-flow rate of the terminal box.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The process of &lt;em&gt;Testing, Adjusting and Balancing&lt;/em&gt; (TAB) of a building HVAC system is meant to deliver sufficient amount
of air, and make sure there will be enough heating and cooling capacity. All the calculation and testing is performed
using building &lt;em&gt;design conditions&lt;/em&gt;. In practice, it is undertaken when building is still unoccupied, during one or a
handful of days (so during a particular season, with specific weather conditions). It doesn‚Äôt cover the actual use of
the building, which will vary over the course of its life: daily changes - with spaces more or less occupied depending
on the hour of the day - and more profound and permanent changes, like when exceptional conditions arise (Covid-19 and 
its cascade of lockdowns), or simply because tenants‚Äô activity changes.&lt;/p&gt;

&lt;p&gt;Another source of HVAC system misconfiguration and excessive energy use is the small and repetitive adjustments made 
over time by people who are responsible for occupants comfort, or to deal with system instability (operational conditions not
tested during initial setup). While it seems natural they make everything they can to guarantee satisfactory living
conditions, this often results in more energy wasted due to narrowed operational behaviour (e.g. raising minimum set
points).&lt;/p&gt;

&lt;h3 id=&quot;non-linearity-in-controlled-systems&quot;&gt;Non-linearity in controlled systems&lt;/h3&gt;

&lt;p&gt;HVAC systems are (highly) non-linear: they will respond non-linearly depending on controlled equipment, command
magnitude, and current state of the system (for instance: cooling or heating mode).&lt;/p&gt;

&lt;p&gt;A classic example can be drawn from &lt;a href=&quot;https://en.wikipedia.org/wiki/Affinity_laws&quot;&gt;fan affinity laws&lt;/a&gt;: &lt;em&gt;pressure is
proportional to the square of shaft speed&lt;/em&gt;. Basically, as fan speed increases, pressure developed by the fan increases
twice faster. This is only from a theoretical perspective though, and many factors will add to make this pressure/speed
relationship even less linear. What does it mean for a classic controller like a PID? It won‚Äôt care, since it has no
knowledge of this, and will vary the output without taking into account that it‚Äôs already in the high end or low end of
the range.&lt;/p&gt;

&lt;p&gt;Another example of non-linear system is heat exchanger, that is used in several HVAC components (heat recovery, hot
water heating plates, ‚Ä¶). Heat exchange efficiency varies depending on the fluid flow rate between which heat transfer
occurs. How much heat exchange efficiency is non-linear depends on equipment capacity, often rated using a
&lt;em&gt;heat transfer coefficient&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 5: heat transfer efficiency at various flows and T¬∞ eff.&lt;/i&gt;
&lt;img src=&quot;/assets/pid_vs_ai/heat_exchange_eff.png&quot; alt=&quot;sources&quot; class=&quot;double-left&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In fig.
5 (&lt;a href=&quot;https://files.danfoss.com/download/Heating/Whitepapers/VFGBC302_optimum-control-of-hex_170407_hires.pdf&quot;&gt;reference&lt;/a&gt;)
, we can see relationship between percentage flow and percentage of heat transferred, for a range of thermal efficiency
between 0.05 and 1 (ideal).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Notes&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;P/P&lt;sub&gt;max&lt;/sub&gt;&lt;/code&gt;: percentage of heat transferred&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;m/m&lt;sub&gt;max&lt;/sub&gt;&lt;/code&gt;: percentage flow&lt;/li&gt;
  &lt;li&gt;thermal efficiency is the ratio between maximum difference in temperature between primary inlet (heating) and
secondary inlet  (heated) fluids, and difference in temperature between primary inlet fluid and primary outlet (
returned to heating system) fluids (equation: &lt;code&gt;&amp;eta;&lt;sub&gt;th&lt;/sub&gt; = (T&lt;sub&gt;11&lt;/sub&gt; - T&lt;sub&gt;12&lt;/sub&gt;) / (T&lt;sub&gt;
11&lt;/sub&gt; - T&lt;sub&gt;21&lt;/sub&gt;)&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;
Using a linear controller, like a PID to control for instance a heating valve is thus going to provide a sub-optimal performance.&lt;/p&gt;

&lt;p&gt;An HVAC system is composed of many non-linear sub-systems, some interacting together with complex relationships.
&lt;strong&gt;It is therefore very limiting to use a linear controller to control equipment that responds non-linearly and have
interactions on many systems.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;supply-air-temperature-sat-and-the-open-loop-problem&quot;&gt;Supply Air Temperature (SAT) and the open loop problem&lt;/h3&gt;

&lt;p&gt;Another common control point in HVAC systems, that is often a target for control optimisation is Supply Air
Temperature (SAT). SAT at air handling unit level is commonly controlled using a temperature set point. In general, 
the set point must be set, so cooled air arriving at the air terminals is cold enough
to meet cooling demand (but reheated at terminal unit level when necessary). In humid climate, the set point is often
set low so to dehumidify (thanks to condensation) the air and avoid moisture problems.&lt;/p&gt;

&lt;p&gt;What do we need to optimise here? SAT set point will have a significant influence on energy consumed by mechanical
cooling, reheat and also supply fan. In order to minimize energy consumption, this set point can be varied using a 
&lt;em&gt;reset&lt;/em&gt; strategy (commonly referred to as &lt;em&gt;SAT set point reset&lt;/em&gt; strategy).&lt;/p&gt;

&lt;h4 id=&quot;why-is-an-open-loop-a-problem&quot;&gt;Why is an open loop a problem?&lt;/h4&gt;

&lt;p&gt;Although &lt;a href=&quot;https://cbe.berkeley.edu/wp-content/uploads/2019/03/Raftery-CostResponsiveReset-May2017.pdf&quot;&gt;many SAT set point reset strategies exist&lt;/a&gt;
, it is still very common to find outdoor air temperature-based reset strategy (&lt;em&gt;OA reset&lt;/em&gt;) used, even in recent
buildings. The assumption is often made, in cold or mild climates that don‚Äôt have high cooling loads, a more
sophisticated approach wouldn‚Äôt worth the pain. It‚Äôs only partially true because a too cold air will require more
reheat, hence also wasting heating energy. Outdoor air temperature-based reset is an &lt;em&gt;open loop problem&lt;/em&gt;: a linear
relationship is assumed between outdoor air temperature and need for cooling. In practice, a linear equation computes
SAT set point based only on outdoor air temperature, without taking into account the actual indoor conditions, leading
to cold complaints problems and high reheat wastes.&lt;/p&gt;

&lt;h4 id=&quot;any-better-yet&quot;&gt;Any better yet?&lt;/h4&gt;

&lt;p&gt;What about more sophisticated strategies then? They are based on heuristics (like the &lt;em&gt;Trim and Respond&lt;/em&gt; logic recently
advertised in &lt;em&gt;ASHRAE guideline 36&lt;/em&gt;) that vary the set point based on cooling demand: air terminal dampers position
and/or cooling valves position is used as input to compute an increase or a decrease of the SAT set point. While it
brings some indubitable benefits, this has some drawbacks too: such an approach requires thorough tuning and testing (
many variables at stake, like number of ignored requests, thresholds to consider for cooling demand, ‚Ä¶) on a
significant period of time (to meet enough variate conditions) and it doesn‚Äôt take into account another highly
non-linear aspect: while SAT set point increases to reduce chilled water use, supply fan speed will increase to respond
to unsatisfied cooling needs (if the supply fan speed is variable and also reset, based on static pressure for instance)
. &lt;br /&gt;
Hence, supply fan electricity use will increase, but this method can‚Äôt tell when increasing SAT set point stops being
advantageous.&lt;/p&gt;

&lt;p&gt;As we‚Äôve seen, there are many ways HVAC system operations can drift from their intended performance. We scratched the
surface of some challenges HVAC engineers, but also building owners and facility managers, struggle with to keep
occupants satisfied while minimising energy consumption of HVAC systems, which accounts in average for 40% of the total
building energy consumption. We‚Äôll now see why and how &lt;em&gt;Artificial Intelligence&lt;/em&gt; (AI) can bring to help taking back
control.&lt;/p&gt;

&lt;h2 id=&quot;what-does-ai-bring-to-hvac-control&quot;&gt;What does AI bring to HVAC control?&lt;/h2&gt;

&lt;p&gt;For almost a decade now, we find usage of AI in all corners of our digital life: image classification, speech
recognition and synthesis, even fake videos generation. A special class of AI technique has drawn attention starting in
2015, called &lt;em&gt;Deep Reinforcement Learning&lt;/em&gt; (DRL). It differs from ‚Äúclassic‚Äù deep learning techniques in that an agent is
trained by interacting with its environment, learning from its mistakes and successes (quantified by a ‚Äúreward‚Äù or a 
‚Äúpenalty‚Äù given to the agent on every action). It has shown incredible successes
with trained agents beating human experts at games like Go or Starcraft, and is used in autonomous vehicles, robotics,
and industry.&lt;/p&gt;

&lt;p&gt;There are some important, fundamental, differences with other learning techniques that make it particularly attractive
for use in process control:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;it can learn in simulated environments, hence data quantity and quality is not a problem. Successful application of 
deep learning has always been limited by lack of good quality data. DRL does not have this limitation.&lt;/li&gt;
  &lt;li&gt;it learns to control: a DRL agent interacts with its environment while trying to maximize the rewards it gets from the
actions it performs. This gives it the ability to test, learn and optimise to their best some control strategies that
no human could ever discover.&lt;/li&gt;
  &lt;li&gt;a domain specialist can encode expert knowledge in the simulated environment and in the reward function to guide the
agent towards expected performance. For instance in a multi-objectives problem, one can choose to reward the agent
more on one objective than another.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are many other differences, some of which are specific to current problem at hand in this article. As a matter of
fact, HVAC systems are an excellent target for control optimization using DRL, and this is an active topic of research:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DeepMind demonstrated this on Google data-centers. There are no official numbers, but Google is now using it generally
to reduce their energy costs. See for instance &lt;a href=&quot;https://deepmind.com/blog/article/deepmind-ai-reduces-google-data-centre-cooling-bill-40&quot;&gt;DeepMind AI Reduces Google Data Centre Cooling Bill by 40%
&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Scientific research on the topic has been very active, as reflects number of papers produced since 2017. A good
example of such a paper
is &lt;a href=&quot;https://ywang393.expressions.syr.edu/wp-content/uploads/2016/07/Deep-reinforcement-learning-for-HVAC-control-in-smart-buildings.pdf&quot;&gt;Deep Reinforcement Learning for Building HVAC Control&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let‚Äôs now detail most important features and compare them with classic HVAC system controllers.&lt;/p&gt;

&lt;h3 id=&quot;seeing-more-than-a-single-input&quot;&gt;Seeing more than a single input&lt;/h3&gt;

&lt;p&gt;A DRL agent can be fed with as many environment observations as wanted (only limited by CPU and memory required to train
and serve the learned control policy). This means it can ‚Äúsee‚Äù current indoor temperatures, outdoor conditions,
mechanical and operation status of the system, ‚Ä¶ Everything that can have an influence of the relevance of its
decisions.&lt;/p&gt;

&lt;p&gt;This makes a significant difference with a classic controller, that usually takes only 1 input. Even if this input is an
aggregation of several observations, this is often insufficient to take an optimal decision. For instance, how to tell
the difference between a damper opened because of a heat demand or a cold demand? This can make a significant difference
in the response to give, depending on a chiller or a heater operational status, and heat exchange properties.&lt;/p&gt;

&lt;h3 id=&quot;learning-system-dynamics&quot;&gt;Learning system dynamics&lt;/h3&gt;

&lt;p&gt;Every building is unique and has its own characteristics in terms of thermal inertia, systems implementation, or
occupancy patterns. More than just learning to cool the air when temperature is high, a DRL agent will learn intrinsic
thermal dynamics of the building, and will be able to give a response in the ‚Äúcorrect proportion‚Äù, without
overshooting or undershooting.&lt;/p&gt;

&lt;p&gt;A simple example of this is fan speed control with holistic knowledge of the environment state: while PID control
strategy described in previous section only looks at most-open damper, DRL agent ‚Äúknows‚Äù about actual thermal conditions
and all other dampers positions. It can therefore adapt its response appropriately. If there is only 1 zone in demand, it‚Äôs 
not the same thing as 2 or 3, as a greater air volume is needed as number of zones increases. A PID would have hard
time not hunting, and as it would take time to stabilise, the system would already be in a different, transient state.&lt;/p&gt;

&lt;p&gt;A benefit of this holistic approach to HVAC control is that one can effectively reduce use of over-sized
equipment, or simply configured to run with very defensive set points. When classic controllers give unsatisfactory
results when system state is at extremes, or simply during transitions, a DRL agent has learned to deal with them
through virtual decades of different, randomised environment conditions.&lt;/p&gt;

&lt;p&gt;Here is a concrete example of these benefits: a HVAC system equipped with a &lt;em&gt;heat recovery machine&lt;/em&gt; saves on heating and
cooling energy by transferring sensible (or total, including latent) heat from return air ducts to supply ones. Heat
transfer efficiency depends on equipment characteristics and air flow rate: basically, the faster the air moves, the
less heat (or cold) can be transferred. A classic controller has no way to take advantage of this property, and will
inevitably push more air as heating or cooling demand increases. A DRL agent controlling the fan will learn that
minimising air flow will improve heat recovery.&lt;/p&gt;

&lt;p&gt;Below graph shows such difference in approach, which leads to a supply air temperature difference of about 5 degrees
between classic and AI control.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/sat_oat_bms_vs_ai.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 6: difference between supply air temperature when Building Management System (BMS) has 
control (03:00 to 07:00) compared to when AI has control (from 07:00 onwards): a much higher, hence energy efficient 
supply air temperature&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;anticipation&quot;&gt;Anticipation&lt;/h3&gt;

&lt;p&gt;A DRL agent learns from a reward it gets on every decision it makes. During the training, every action leads to a state
of the system, which is used to compute this reward. The purpose of the training (or teaching) is to make the agent 
&lt;em&gt;maximize the sum of its rewards&lt;/em&gt;. So not every single reward separately, but a couple of them. Intuitively, this
introduces a very fundamental: we are more interested in the overall result than by each decision taken separately, so
the control strategies the agent can discover are very different.&lt;/p&gt;

&lt;p&gt;Some concrete examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;agent may take decision that seems bad (in terms of instant reward) but that will lead to much better results on
consecutive ones. For instance, to minimize power demand when energy price is highest, agent may decide to cool spaces
in advance, lowering electricity demand when actual cooling demand should be highest (afternoon).&lt;/li&gt;
  &lt;li&gt;along with learned building thermal dynamics, anticipation of HVAC end of operations (when scheduled) can lead to
interesting strategies: agent will learn to reduce equipment use by just the right proportion until end time is
reached, while maintaining desired comfort. A classic control would just push things as usual, as it has no knowledge
of thermal dynamics or schedules.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Anticipation, as an inherent feature of reinforcement learning, also brings a difference with other AI and deep learning
techniques like forecast. In time series forecast, a model is trained to predict next few minutes or hours of one or
more variables given some observations. This can be used to predict, for instance, what the indoor temperature will be
given past indoor, outdoor and system conditions. With such technique, each decision goes isolated from each other, and
there is no simple way to build strategies that span multiple control steps.&lt;/p&gt;

&lt;h3 id=&quot;testing-hypotheses-and-strategies-in-days-not-months&quot;&gt;Testing hypotheses and strategies in days, not months&lt;/h3&gt;

&lt;p&gt;When a building HVAC system requires a partial or entire retrofit, the project takes from several months to years before
achievement. As it involves hardware changes, and very important expenses, an &lt;em&gt;energy performance audit&lt;/em&gt; is conducted to
assess current building strengths and weaknesses, and prescribe upgrades that would be the most cost effective 
(depending on goals, but &lt;em&gt;return on investment&lt;/em&gt; is often key).&lt;/p&gt;

&lt;p&gt;This is where simulation can take place: using a detailed building model, calibrated against historical energy
consumption, auditors can test various scenarios and simulate their efficiency. It offers a way to make educated, data
driven decisions, and not relying only on experience. The exact same basis can be used to train a deep reinforcement
learning agent to control HVAC equipment: since the building model that serves as training environment is calibrated,
not only the agent is learning from a realistic environment, but its achievements and performance will have solid
ground.&lt;/p&gt;

&lt;p&gt;Figure 7 shows an overview of a &lt;em&gt;digital twin&lt;/em&gt; acquisition process (calibrated building model) used to train deep 
reinforcement learning agents to obtain optimal HVAC control policies, that can be later deployed to control actual 
building HVAC system.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/hvac_training_workflow.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 7: a digital twin acquisition, DRL agent training and deployment workflow overview&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;The comparison with classic retrofit projects stops here though: when it will often take months or even years to
finalize an HVAC hardware upgrade, a DRL control policy can be deployed in days. Apart from the obvious improvement in
duration, such work-flow is a real plus for building owners and property managers, since it relies on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a clear and standardised modelling and calibration process (e.g. calibration is backed by ASHRAE guideline 14)&lt;/li&gt;
  &lt;li&gt;a cost-effective simulation process to test strategies&lt;/li&gt;
  &lt;li&gt;an additional and valuable asset (the building model itself) that concentrates all necessary information about the
building, for present and future projects&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Simulation engines, as a source of training data for deep reinforcement learning, have other key benefits compared to other solutions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;they produce an infinite stream of data of excellent quality (historical data can be sparse, noisy, hard to interpret
and parse, sometimes unusable)&lt;/li&gt;
  &lt;li&gt;they give a holistic view of building conditions: you can simulate indoor air quality (rarely available in building
historical data), randomized conditions, etc.&lt;/li&gt;
  &lt;li&gt;agent can be prepared to worst case scenarios: extreme weather, HVAC faults, ‚Ä¶ Something that is hard to get
otherwise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Figures 8a and 8b illustrate HVAC optimization proposals one can easily test in a couple of days using a calibrated model
and DRL.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/sim_bench_bar.png&quot; alt=&quot;sources&quot; class=&quot;double-left&quot; /&gt;
&lt;img src=&quot;/assets/pid_vs_ai/sim_bench_tab.png&quot; alt=&quot;sources&quot; class=&quot;double&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;margin-top:80px; width:100%&quot;&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 8a,b: results in percent savings on a benchmark between classic control and AI-based solutions&lt;/i&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;There‚Äôs also a clear difference with forecast-based techniques, which can only rely on historical data from the
building. Historical data from Building Management System (BMS) or other sources is often scarce, if ever present. With
scarce data, you are limited to what the model can learn from, so the number of potential strategies will be small. If
you don‚Äôt have enough data, the only thing you can do is‚Ä¶ wait! Several months at least, because the model needs to be
trained on different weather conditions to produce satisfactory results. Imagine you collect only data during summer,
what happens in winter when the model is proposed with unseen conditions is likely to be arbitrary decisions. If we
generalize, it‚Äôs very likely that a forecast model will take years to be self-sufficient, the time it takes to collect
enough data.&lt;/p&gt;

&lt;h3 id=&quot;additional-benefits&quot;&gt;Additional benefits&lt;/h3&gt;

&lt;p&gt;Something that is harder to quantify, but has reasonable logical ground, is that making control more stable increases
mechanical equipment lifespan. By anticipating needs and taking only one action every few minutes, AI can help avoiding
turning equipment on and off constantly, but most importantly solves poor programming control logics.&lt;/p&gt;

&lt;p&gt;Taking fan speed control as an example, we saw already in previous examples some diseases a fan can suffer from,
like large oscillations throughout the day, likely because of its controller characteristics but also due to how its
input varies: static pressure reset or most-open damper control strategies can bring instability. As a result, the fan
speeds up and slows down throughout the day, wasting energy in acceleration and deceleration, some of which is simply
expelled as heat. This added to the constraint supported by the fan belt, will eventually decrease fan lifespan.&lt;/p&gt;

&lt;p&gt;On the other hand, AI, thanks to its anticipation capability, doesn‚Äôt need to constantly react to changes in input. With a
multimillion time steps training, and practical training constraints, a reinforcement learning agent learns to keep
control stable and to avoid large changes. HVAC equipment, with thousands of dollars cost for each piece, is preserved
longer.&lt;/p&gt;

&lt;h3 id=&quot;results-in-an-actual-building&quot;&gt;Results in an actual building&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pid_vs_ai/hdd_bms_ai_lr.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i class=&quot;image-foot&quot;&gt;fig. 9: performance comparison between control provided by AI and by BMS, 
 based on 18¬∞C-based normalised Heating Degree Days (HDD) over a 90 days period&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Above chart shows results obtained by multiple deep reinforcement learning agents that took control of HVAC equipment in
an actual commercial building. From day 1, they have been efficient and proved to adapt well to changing conditions.
Taking denormalized results on this 3 months period (100% of the period), they obtained &lt;strong&gt;47% savings in $&lt;/strong&gt; compared to
previous years utilities bills data. Using normalized results (typical office hours), savings were up to &lt;strong&gt;65%&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we‚Äôve seen how artificial intelligence, and deep reinforcement learning in particular, is well 
suited for HVAC control optimizations. With a cost-effective and robust process based on building models, calibration and 
teaching in simulated environment, efficient control policies can be discovered to achieve significant savings.&lt;/p&gt;
</description>
        <pubDate>Sun, 24 Jan 2021 01:00:00 +0100</pubDate>
        <link>https://airboxlab.github.io//hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//hvac/control/ai/reinforcement_learning/2021/01/24/smart_control.html</guid>
        
        
        <category>hvac</category>
        
        <category>control</category>
        
        <category>ai</category>
        
        <category>reinforcement_learning</category>
        
      </item>
    
      <item>
        <title>Data Science at Airboxlab - Part 2</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
&lt;/style&gt;

&lt;p&gt;This is the second article in a series of 2 (&lt;a href=&quot;/data_science/2018/07/01/data_science_at_abl_p1.html&quot;&gt;1st article here&lt;/a&gt;) about how we see and do data science at &lt;a href=&quot;https://foobot.io&quot;&gt;Airboxlab&lt;/a&gt;. This article delves into technical aspects, and presents data collection processes, pipelines, machine learning and infrastructure we have in place.&lt;/p&gt;

&lt;h3 id=&quot;what-we-do&quot;&gt;What we do&lt;/h3&gt;

&lt;p&gt;Let‚Äôs first explain main tasks we‚Äôre trying to tackle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/pipeline_ml.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Overview of an end-to-end ML pipeline&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Correlations &amp;amp; causal inference&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Looking for correlations, or better, causality, is a discipline that applies to a variety of situations. For instance when there is a doubt about a device feature that may have a side effect on another, or when we want to know what causes users to develop a particular habit or act a specific way. Another interesting application is to find how user habits or external factors like outdoor air pollution reflects on sensor data. A great example of one of our recent study demonstrates a temperature side effect called &lt;a href=&quot;https://foobot.io/resources/off-gassing/&quot;&gt;off-gassing&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analytics and visualizations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Probably the most common aspect of data science: extracting value (metrics, KPIs, charts) from data and communicate it to stakeholders. In IoT, monitoring and analysing devices life cycle represents a significant part of this job. For instance, checking effect of a firmware release on a product (e.g has connectvity improved? how many upgrades are failing?). An other less common aspect is reporting about manufacturing: we build our own test equipments for products we manufacture, and of course these small servers (we call them &lt;em&gt;test rigs&lt;/em&gt;, they help testing electrical boards and components directly on the manufacturing assembly line) send us a lot of data from different factories. Consolidating this and detecting problems is crucial.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Machine learning to solve complex problems&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Machine learning can be applied where problems start to be hard to solve with basic analytics or simple statistics. Modeling and productizing ML models adds significant overhead in terms of complexity and engineering, so we‚Äôre always cautious about how and when to apply ML. However, some of the problems we face require this level of sophistication in order to get an appropriate solution.&lt;/p&gt;

&lt;p&gt;One of them is device calibration: we do real time calibration on some of sensors using regressions. A bit trickier, we developed (but still improving) air quality events detection and classification, using clustering, supervised and semi supervised learning techniques.&lt;/p&gt;

&lt;p&gt;Some of our current biggest challenges also involve machine learning, like automatic hardware/software failures detection, maintenance prediction or automatic ventilation systems control (provide clean air without human intervention, no matter what activity is going on).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stream processing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Stream processing is inherent to IoT as we often need to react within a few seconds or minutes to events. A traditional batch approach doesn‚Äôt suit well in that case. For that purpose we use a stream processing framework along with appropriate techniques (like aggregations on sliding windows) and statistics (like moving averages). We also ship machine learning models in our real time pipeline so we can make predictions on fresh data (e.g. air quality classification).&lt;/p&gt;

&lt;h3 id=&quot;how-we-do-it&quot;&gt;How we do it&lt;/h3&gt;

&lt;p&gt;Diving deeper into technical matters, here are details about how data is processed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data pipelines&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/pipelines_infra.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Pipelines technical overview&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;We have 2 main types of pipelines: the hot path - &lt;em&gt;near real time processing pipelines&lt;/em&gt; - and the cold path - &lt;em&gt;analytics pipelines&lt;/em&gt; (batches). We generally use the hot path when a response is needed within a few minutes (max 1h), and batches otherwise.&lt;/p&gt;

&lt;p&gt;Near real time processing serves the purpose of creating running/moving aggregations, reacting to events and sending alerts, or predicting using models. Batching is about creating new datasets and populating our data warehouse with data that will be used later.&lt;/p&gt;

&lt;p&gt;The cold path is implemented first using ELT pattern (Extract Load &amp;amp; Transform as opposed to ETL): data we have is sent to our data lake without pre-processing, filtering or formatting of any sort. Schema is applied on read, mainly with transformers jobs that populate the warehouse, or when data analyst requires access to ‚Äúraw‚Äù values. ELT pattern is particularly suitable to IoT as devices can fail, send inconsistent data, and data schemas can change rapidly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/data_infra.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;ELT infrastructure overview&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Pipelines are then created by first dumping into the data lake, then pumping it into our data warehouse or through analytics jobs. As it‚Äôs easy to create new data sets and new pipelines, number of tables we have to handle grows rapidly (but we try to compensate with good documentation).&lt;/p&gt;

&lt;p&gt;Most of our datasets are built on top of logs: every change is persisted with a timestamp (event time when available, processing time otherwise), which let‚Äôs us investigate things with accuracy.
Eventually, the amount of data to store is much bigger, but it contains vital information, and we apply patterns like event sourcing to take full advantage of it. Also, most statistical programming language or framework (R, python‚Äôs pandas, SQL, Spark) have convenient routines and operators to deal with time series like these (lead/lag, rank, correlation operators, ‚Ä¶)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/aggreg.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Sample aggregations from logs&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Collaboration&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;One of our favorite collaboration tool is notebooks. We‚Äôre using Spark all the way down the data processing line, and &lt;a href=&quot;https://databricks.com/&quot;&gt;Databricks&lt;/a&gt; for most of our projects. Notebooks offer a perfect environment for sharing ideas, presenting results and demonstrating new analytics or algorithms. It‚Äôs also development cycle-friendly as it integrates with source code versioning (git).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data products&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All that we do don‚Äôt always ship in production, but most of the time it does. When it comes to productizing, tasks like exposing an API endpoint, or creating a new view in our apps, are required. Recently, data science work we shipped in production include real time air quality classification, sensor calibration functions, and in app analytics.&lt;/p&gt;

&lt;p&gt;Data products are complex artifacts to handle in terms of development, especially when ML is involved, as we‚Äôre adding complexity and new potential problem sources (data &amp;amp; models) to something already complex (coding). When it comes to shipping data science work in production, it can get tricky too: validation, user testing, or deployment require careful handling. That‚Äôs why we‚Äôre relying on a few reliable frameworks (like Spark) and techniques (like cross validation or A/B testing).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data as a service&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A data warehouse is a good solution to apply a schema and extract value from large datasets. It‚Äôs also great to provide a simple way for data analysts or business people to interact with data. As there is often a ‚Äúmissing dimension‚Äù in your last chart, why not let them explore data and see what they can find? Of course this requires business users to be guided and learn some SQL basics. Alternatively, pre-defined data sources and charts can be a great asset for teams without sufficient technical knowledge to access data directly.&lt;/p&gt;

&lt;p&gt;On our side we‚Äôre now using &lt;a href=&quot;https://superset.incubator.apache.org/&quot;&gt;Apache Superset&lt;/a&gt; which provides the best of both worlds, as it brings SQL capabilities with a great way of creating data sources (tables) and charts (slices). It‚Äôs easy for non technical users to pick existing assets, modify them, and create their own visualizations.&lt;/p&gt;

&lt;p&gt;Another data exploration channel we‚Äôre exploring is accessing our data lake and warehouse (stored in S3) with new tools like &lt;a href=&quot;https://aws.amazon.com/athena/&quot;&gt;AWS Athena&lt;/a&gt;. You can manage a catalog of data sources, schemas, and query data directly from there using SQL without worrying about infrastructure. Powerful.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In this series of 2 articles, we‚Äôve tried to give an overview of how we use data at Airboxlab and why. So far, this has been beneficial to many projects.&lt;/p&gt;

&lt;p&gt;We are dedicated to continuous improvement and scaling of our data science process. There are big challenges ahead, and expectations are high.&lt;/p&gt;

&lt;p&gt;Data is more than ever fueling products design, experimentations and discoveries, helping us innovate.&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Sep 2018 14:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//data_science/2018/09/21/data_science_at_abl_p2.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//data_science/2018/09/21/data_science_at_abl_p2.html</guid>
        
        
        <category>data_science</category>
        
      </item>
    
      <item>
        <title>Data Science at Airboxlab - Part 1</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.center {
    display:block;
    margin: 0 auto;
}
&lt;/style&gt;

&lt;h3 id=&quot;data-science-at-airboxlab&quot;&gt;Data Science at Airboxlab&lt;/h3&gt;

&lt;p&gt;This is a series of 2 articles that dives into data science discipline at &lt;a href=&quot;https://foobot.io&quot;&gt;Airboxlab&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;1st article (present one) is about the data-driven philosophy we have in our company, and how work is organized around it&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/data_science/2018/09/21/data_science_at_abl_p2.html&quot;&gt;2nd article&lt;/a&gt; depicts main problems we try to solve by applying data science, and how it is technically designed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;investing-in-data&quot;&gt;Investing in data&lt;/h3&gt;

&lt;p&gt;Designing air quality monitors has a lot to do with data: real-time air quality readings are useful to our users in many cases: they can act directly whenever air quality degrades, or setup home automations using Nest, Ecobee, IFTTT or other integrations we developed to automate ventilation systems based on air quality. 
But some key elements are missing: as a user, how do I know what the main pollution source is in my home? What can I do about it and when did air quality really start to degrade? Moreover, how efficient is the solution I have just put in place? These are some of the questions that require long term analysis and accurate responses.&lt;/p&gt;

&lt;p&gt;There are many other areas where data analysis shines and where it can add value. For example how is air quality affected by common external factors (like outdoor particles, &lt;em&gt;NOx&lt;/em&gt;, weather, ‚Ä¶), what habits a user has is able to bring the best solution or worsen air quality. One may also be interested in knowing how sensors behave and age in varying conditions: some sensors require calibration at different phases in their life, and some others react to external factors.&lt;/p&gt;

&lt;p&gt;This article is about how the data science discipline can help us in creating value for our users and how central the discipline is in the development of our products.&lt;/p&gt;

&lt;h3 id=&quot;our-gems&quot;&gt;Our gems&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/streams.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Airboxlab data sources&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;There are multiple data streams ingested by our data platform, the 3 main being the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Device‚Äôs data&lt;/strong&gt; coming from our units in the wild. Depending on the product, there can be from 5 to 20 sensors continuously sent by devices, to which we can add aggregations, error codes and unprocessed values also computed by the device itself. Some devices (like air purifiers) send commands and status about other components (like change of fan speed)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;User‚Äôs data&lt;/strong&gt; coming from apps and dashboards. Think user profile, user interactions ‚Ä¶&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Outdoor data&lt;/strong&gt; integrated from external providers. It includes sources of outdoor pollution and weather.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Additional data coming from different sources are also used on a day to day basis. Some of them have dedicated ingestion pipelines (e.g. server logs from operations), some others are ephemeral (e.g. an archive file containing pollen data for a specific area in order to check a correlation).&lt;/p&gt;

&lt;p&gt;Compared to other IoT companies, we have kind of an advantage in that we design air quality monitors and air purifiers, but we also develop embedded software for them which sends data to our own services in the cloud, and we are able to update their embedded software (firmware) at anytime if needed. The whole data acquisition process is in our hands. That means that if a team member needs explanations about some new sensor value or if a next generation device needs to send metrics differently, we are able to quickly refer to the person sitting next us.&lt;/p&gt;

&lt;p&gt;As an engineering company with data-driven processes at its heart, data quality is a matter of high importance. Data quality is never overlooked, trade-offs are often in favor of preserving quality. As a result, &lt;strong&gt;our data streams and data lake are well documented, pipelines are written in a way that fosters high quality data sources and sinks, and everyone in the company cares about it&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;our-goals&quot;&gt;Our goals&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/ooda_loop.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Simplified data-driven decision process&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Data Science team ‚Äúcustomers‚Äù are both internal (business, but also tech teams who wants to find ways of improving reliability of our sensors, services or infrastructure), and external (our users, who are our main concern, and external partners, who want to keep track of their unit fleets with various metrics - manufacturing line metrics, sensors drift over long period of time, ‚Ä¶).&lt;/p&gt;

&lt;p&gt;Data is central in IoT. This makes an important difference when it comes to our day-to-day duties: &lt;strong&gt;extracting value out of data matters because products and features are built on top of it&lt;/strong&gt;. For our CEO, hardware engineers, project managers or sales people, it‚Äôs a source of truth for designing products, improving user experience or advertising about our expertise. This isn‚Äôt like we had sit on a huge pile of undocumented data sources for years then realized this could be of interest: we cared from day 1. As a consequence, data science is one of the hottest topic in the company, and we work with enlightened people who knows what to expect.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data driven decisions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Our company sells primarily technology, and services around it. Data is key in the decision process in a wide variety of fields like new sensors assessment and selection, or new features development in mobile and web applications.&lt;/p&gt;

&lt;p&gt;Our decision process includes answering &lt;em&gt;data questions&lt;/em&gt; early, with dedicated communication channels, like our internal Slack #data channel where questions are raised and where discussion begins.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analytics &amp;amp; ML products (user-facing features or not)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We have around 20+ projects where data science is involved, and often key component of the project. It ranges from in-app analytics to hardware failure detection. Not all projects require the same set of skills or data science assets, and not all involve machine learning. But machine learning is ranking often high in our projects options list as complexity is kicking in and amount of data to deal with gets bigger.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Indoor Air Quality expertise&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Air quality is a complex topic and there are tons of things we learn every time we dig into our data sources. We try to build a knowledge database from that so we can make our users benefit from it. It also applies to hardware components we select and ship in our products - especially sensors - as there are lot of different ones, with different behaviours and capabilities, aging mechanism, etc. It‚Äôs a great source of information for building new products.&lt;/p&gt;

&lt;h3 id=&quot;projects-organization&quot;&gt;Projects organization&lt;/h3&gt;

&lt;p&gt;We‚Äôre a small shop, so it‚Äôs crucial for people working with us to go beyond traditional role boundaries. Regarding data science, scientist is involved in business requirements gathering, data engineering (defining what data, at what frequency, ‚Ä¶), productionizing models (e.g. embedding model in a real time pipeline), creating visualizations and communicating results. It‚Äôs an intense mission, but it comes with the reward of mastering the whole data life cycle.&lt;/p&gt;

&lt;p&gt;This is also true for business people: while technical people may not be always available to answer data-related questions, it‚Äôs better if they can look by themselves. This requires well organized and documented datasets, as well as simplified access to data: saved SQL queries, table views, charts templates‚Ä¶ So this can turn into a real efficient process. This is called &lt;strong&gt;data as a service&lt;/strong&gt; and it requires more than some tools or a dashboarding solution: making data available to others inside the company is also about communication.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ds_abl/ds_workflow.png&quot; alt=&quot;sources&quot; class=&quot;center&quot; /&gt;&lt;/p&gt;
&lt;center&gt;&lt;i&gt;Work-flow and ownership&lt;/i&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The team.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Our backend team is composed of seasoned developers, who like to work on complex problems and huge datasets. With data science field gaining maturity, and ecosystem evolving rapidly towards more developer-friendly frameworks, it‚Äôs now doable for us to tackle complex projects. The most important thing about that is we‚Äôre intimate with the whole data process, which &lt;strong&gt;removes the traditional barriers of moving a project from concept phase towards product&lt;/strong&gt;. With the number of projects grows our expertise in analytics and ML.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;In this 1st article we have exposed Airboxlab data science process and vision, from a functional perspective. Next article dives into more technical things, like data pipelines design and types of data-related tasks we‚Äôre tackling.&lt;/p&gt;
</description>
        <pubDate>Fri, 21 Sep 2018 13:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//data_science/2018/09/21/data_science_at_abl_p1.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//data_science/2018/09/21/data_science_at_abl_p1.html</guid>
        
        
        <category>data_science</category>
        
      </item>
    
      <item>
        <title>Scaling MQTT connections with RabbitMQ - Part II</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.callout {
    float: right;
    margin-left: 5px;
}
&lt;/style&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/scale_mqtt_2/drink-out-of-a-hose.jpg&quot; alt=&quot;firehose&quot; class=&quot;callout&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We‚Äôve been running our messaging gateways with a more distributed approach as described in &lt;a href=&quot;part I&quot;&gt;&lt;/a&gt; for more than a year now, and wanted to share problems we faced and solutions we found.&lt;/p&gt;

&lt;p&gt;First of all, let‚Äôs face it: it has been a shaky road. After an initial period of a few weeks where everything seemed to run smoothly under control, new incidents and outages started to show up intermittently. This was due to several problems I describe here.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;aws-ec2-instances-choosing-the-right-type&quot;&gt;AWS EC2 instances: choosing the right type&lt;/h4&gt;

&lt;p&gt;When we deployed our new version in May 2017, we chose cheap instance types like &lt;em&gt;t2&lt;/em&gt; for our proxies, with the idea of scaling them in mind.&lt;/p&gt;

&lt;p&gt;It revealed to be a bad choice: &lt;em&gt;t2&lt;/em&gt; network interfaces are flaky and we suffered several hiccups, with massive reconnection events as a result. They are also not well suited for medium to long burst periods, as cpu access is throttled after a few 10a of minutes running above credit line. And we needed that to deal with recovery during massive reconnection events.&lt;/p&gt;

&lt;p&gt;Finally a bunch of weak instances compared to a fewer but stronger ones is strategically a non sense here: more maintenance, less predictability.&lt;/p&gt;

&lt;p&gt;Our current gateways now use &lt;em&gt;m4&lt;/em&gt; instance family. Since that, network hiccups have disappeared.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;haproxy-timeouts&quot;&gt;HAProxy timeouts&lt;/h4&gt;

&lt;p&gt;At first we‚Äôve let default or too high values for some we didn‚Äôt know about. Problem with persistent MQTT connections and nextwork connections from resource-constrained hardware is that you may endup with a lot of idle, half-opened connections that could pile up and prevent legitimate connections to open.&lt;/p&gt;

&lt;p&gt;Hopefull for us, HAProxy has a very flexible configuration. And an extensive documentation. It‚Äôs possible to configure client, server and other type of timeouts. Here is an extract of one of our configs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-cfg&quot;&gt;defaults
    mode    tcp
    option  abortonclose
    timeout client      30s
    timeout client-fin  15s
    timeout connect     5s
    timeout server      30s
    timeout server-fin  15s
    timeout queue       30s
    timeout tunnel      30s
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some values may seem a bit aggressive but since MQTT clients are all configured to automatically reconnect, it‚Äôs fine.&lt;/p&gt;

&lt;p&gt;One important thing to note is HAProxy &lt;em&gt;timeout tunnel&lt;/em&gt; supersedes &lt;em&gt;timeout client&lt;/em&gt; and &lt;em&gt;timeout server&lt;/em&gt;, for persistent connections it‚Äôs an important one to set. Also HAProxy doc recommends using &lt;em&gt;timeout client-fin&lt;/em&gt; and &lt;em&gt;timeout server-fin&lt;/em&gt; in conjunction, to close sockets in &lt;em&gt;FIN_WAIT&lt;/em&gt; state faster.&lt;/p&gt;

&lt;p&gt;Finally, in order to maintain connections open, MQTT clients are using heartbeat messages with interval &amp;lt; 30s.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;mqtt-clients-tuning&quot;&gt;MQTT clients tuning&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Clean session &amp;amp; QoS 1&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;clean session&lt;/em&gt; is a MQTT flag that instructs server it can remove everything belonging to the client and connection is closed. We‚Äôve used it to ensure we don‚Äôt end up in situations where a RabbitMQ cluster node would refuse a connection because a MQTT queue was still present on an other node (we finally gave up using RabbitMQ clustering, but we may come back to it one day).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;QoS 1&lt;/em&gt; is the intermediate level of guarantee for MQTT messages delivery. It ensures messages are delivered &lt;em&gt;at least once&lt;/em&gt; to the receiver (hence doesn‚Äôt guarantee the same message isn‚Äôt received several times).&lt;/p&gt;

&lt;p&gt;Also, &lt;em&gt;TTL&lt;/em&gt; on messages is fairly low (never more than 30s) so they are lost when they aren‚Äôt consumed fast enough. This to prevent filling up queues on server side.&lt;/p&gt;

&lt;p&gt;In order to cope with this client &amp;amp; server technical constraints, we also added a couple of application-level safeguards:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;important messages are resent to receivers upon connection. Even in case of short disconnection&lt;/li&gt;
  &lt;li&gt;idempotency and statelessness are enforced: state is preserved in the backend, which decides when and how to send messages. MQTT clients are designed to support receiving same message several times. RabbitMQ only passes messages, doesn‚Äôt store them.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Exponential backoff&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;MQTT clients may disconnect for different reasons: flky network quality, server-side closed, you name it. MQTT library we wrote is made to take care of reconnecting automatically. In order to avoid self-inflicted DDoS, clients will retry indefinitely but with an exponentially-increasing delay between each attempt every time.&lt;/p&gt;

&lt;p&gt;As we were testing this, we noticed that this principle must be extended up to the reception of the first MQTT heartbeat answer from server: it‚Äôs only at that moment we know server is fully operational.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;rabbitmq-tuning&quot;&gt;RabbitMQ tuning&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;no more clustering&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;RabbitMQ clustering let‚Äôs you form clusters of nodes with the benefit of possible fail-over in case of node failure, or queues high availability. However it‚Äôs not well suited for load-balancing tens of thousands of connections.&lt;/p&gt;

&lt;p&gt;First of all, communication overhead between nodes is significant and requires to keep nodes in the network to prevent latency. Second, recovery and upgrade are far more complex than with a collection of single nodes. 
Last but not least, RabbitMQ suffers a bug that‚Äôs not directly linked to clustering, but gets worse because of it: in case of node shutdown or massive reconnection, thousands of auto-delete queues get evicted. This triggers a Mnesia (distributed DB RabbitMQ is using) lock contention and it can get up to several minutes for the node to recover from that. See &lt;a href=&quot;https://groups.google.com/d/msg/rabbitmq-users/hgRmhpL8Y6o/F7UoGyDsCwAJ&quot;&gt;this dicussion on RabbitMQ users list&lt;/a&gt; and related &lt;a href=&quot;https://github.com/rabbitmq/rabbitmq-server/issues/1566&quot;&gt;bug opened&lt;/a&gt; (not fixed in 3.6 yet).
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;os-tuning-sysctl-tcp-stack--network-interfaces&quot;&gt;OS tuning: sysctl, TCP stack &amp;amp; network interfaces&lt;/h4&gt;

&lt;p&gt;Our current architecture pairs several RabbitMQ nodes with 1 HAProxy instance. HAProxy resources consumption is pretty low for that type of workload so it‚Äôs possible to achieve hundreds of thousands of connections with a single HAProxy instance.&lt;/p&gt;

&lt;p&gt;In order to that, there‚Äôs a major OS constraint that limits number of outbound connections for a specific IP. This is first controlled by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;net.ipv4.ip_local_port_range&lt;/code&gt; sysctl option (very low by default on most distributions). But the maximum is &lt;em&gt;65535&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There are several ways to go beyond, we chose to use AWS ENIs (Elastic Network Interface): our instance setup script allocates 4 ENIs then configures each network interface. Finally, it can be used n HAProxy configuration as following:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;backend tcp-out-1883
    default-server inter 30s rise 2 fall 2
    timeout check 5s
    option tcp-check
    server server1-eni1 10.0.2.1:1883 source 10.0.1.1 check on-marked-down shutdown-sessions
    server server1-eni2 10.0.2.1:1883 source 10.0.1.2 check on-marked-down shutdown-sessions
    server server1-eni3 10.0.2.1:1883 source 10.0.1.3 check on-marked-down shutdown-sessions
    server server1-eni4 10.0.2.1:1883 source 10.0.1.4 check on-marked-down shutdown-sessions
    server server2-eni1 10.0.2.2:1883 source 10.0.1.1 check on-marked-down shutdown-sessions
    server server2-eni2 10.0.2.2:1883 source 10.0.1.2 check on-marked-down shutdown-sessions
    server server2-eni3 10.0.2.2:1883 source 10.0.1.3 check on-marked-down shutdown-sessions
    server server2-eni4 10.0.2.2:1883 source 10.0.1.4 check on-marked-down shutdown-sessions
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;em&gt;10.0.2.X&lt;/em&gt; are RabbitMQ nodes and &lt;em&gt;10.0.1.X&lt;/em&gt; are HAProxy network interfaces.&lt;/p&gt;

&lt;p&gt;There are also a couple other sysctl options that can be tuned. &lt;a href=&quot;https://www.rabbitmq.com/networking.html&quot;&gt;RabbitMQ documentation&lt;/a&gt; gives some recommendations.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;testing-a-load-testing-framework&quot;&gt;Testing: a load testing framework&lt;/h4&gt;

&lt;p&gt;How can one validate settings at various levels without testing? For this purpose we created a small test framework that interacts with AWS EC2 and spawns desired number of instances, and execute several thousands of MQTT clients on each of them. MQTT client is using &lt;a href=&quot;https://www.eclipse.org/paho/&quot;&gt;Eclipse Paho&lt;/a&gt; library and is configurable (number of clients, ramp up period, interval between messages, QoS level, clean session).&lt;/p&gt;

&lt;p&gt;This helped us validating client, server, OS, and software configurations, as well as finding the right amout of CPU/RAM required for the load.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;automating-operations&quot;&gt;Automating operations&lt;/h4&gt;

&lt;p&gt;It sounds obvious, but we didn‚Äôt have an end-to-end automated way of recreating our messaging gateways infrastructure. We know have ~90% scripted.&lt;/p&gt;

&lt;p&gt;It‚Äôs of great help during testing phase, as we were able to simply trash a whole set of instances and configurations and restart from scratch. Now we use it for scaling operations.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;high-availability-with-aws-route53&quot;&gt;High Availability with AWS Route53&lt;/h4&gt;

&lt;p&gt;This was one of our goals in first article I wrote: we were first relying on clustering for HA, but it was only able to deal with AWS Availability Zone failures.&lt;/p&gt;

&lt;p&gt;We implemented HA at a higher level, without RabbitMQ clustering. It‚Äôs using AWS Route53 and a combination of geo-location, weight and healtcheck rules to decide where to send clients. This offers both intra and cross region failover.&lt;/p&gt;

&lt;p&gt;The whole thing is well described in &lt;a href=&quot;https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html&quot;&gt;this document&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;final-notes&quot;&gt;Final notes&lt;/h2&gt;

&lt;p&gt;We incrementally released this new version of our messaging infrastructure in December 2017 and January 2018. It proved to be a good move as we significantly recuded number of incidents and maintenance time, while improving scalability. There‚Äôs still work to do though!&lt;/p&gt;

&lt;p&gt;Our next goals are about finalizing automation of gateway provisioning and setup. With that, we will be able to implement auto scaling: our workload doesn‚Äôt vary much, but in case of instance failure, automatically spawning and configuring a new can be a major improvement.&lt;/p&gt;

</description>
        <pubDate>Mon, 23 Apr 2018 10:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//iot/mqtt/scalability/rabbitmq/haproxy/2018/04/23/scaling_mqtt_part2.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//iot/mqtt/scalability/rabbitmq/haproxy/2018/04/23/scaling_mqtt_part2.html</guid>
        
        
        <category>iot</category>
        
        <category>mqtt</category>
        
        <category>scalability</category>
        
        <category>rabbitmq</category>
        
        <category>haproxy</category>
        
      </item>
    
      <item>
        <title>Scaling MQTT connections with RabbitMQ</title>
        <description>&lt;h2 id=&quot;suddenly-it-failed&quot;&gt;Suddenly, it failed&lt;/h2&gt;

&lt;p&gt;It happened at the beginning of 2017. Our number of clients had grown steadily so far, and we were confident our current MQTT clusters configuration was strong enough to cope with it for a while.&lt;/p&gt;

&lt;p&gt;Wrong! So wrong! While we were quietly preparing for weekend leave, several alarm bells rang: rabbitmq node 1 not responding, then another, finally the entire cluster. Ok, no worries, let‚Äôs just restart it. Wrong again! While it‚Äôs easy to change a tire on a stopped car, doing it when you‚Äôre driving at 200 km/h is another thing: clients trying to automatically reconnect were preventing a smooth restart. After several unsuccessful attempts, lot of sweat, and placing the cluster in a safe mode, we finally managed to get it back to work.&lt;/p&gt;

&lt;h2 id=&quot;after-the-storm-time-to-look-back&quot;&gt;After the storm, time to look back&lt;/h2&gt;

&lt;p&gt;With this painful event, we realized we were still operating our message brokers, and everything around, as if they were handling a few hundreds of clients. Although we knew we would have to strengthen this core part of our infrastructure, it wasn‚Äôt showing any sign of weakness. The danger of things working well is you quickly forget them! And in a small but rapidly growing shop like ours, priorities change. Still, reality strikes back to make you face all the things you are missing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;strong isolation&lt;/strong&gt;: a single message brokers cluster that does everything (internal/external communication) is very convenient at the beginning: it‚Äôs cheap and easy to setup. But one piece failing and the entire system is out. Also, upgrading or simply tuning becomes a stressful operation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;performance tests&lt;/strong&gt;: what are our needs if number of clients double? Are we able to deal with forecasted throughput? What happens under flaky network conditions? What harwdware for that?&lt;/li&gt;
  &lt;li&gt;clear &lt;strong&gt;disaster recovery procedures&lt;/strong&gt;: a document with some basic steps isn‚Äôt enough. Let‚Äôs learn from disasters, and shape up a correct recovery plan with realistic scenarios and steps.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article focuses on 1st point (but we worked also on the others, performance tests were one of the prerequisites for developing the solution).&lt;/p&gt;

&lt;h2 id=&quot;divide-and-conquer&quot;&gt;Divide and conquer&lt;/h2&gt;

&lt;p&gt;We expose our services through different APIs and protocols, but most of the activity comes from asynchronous messages processing that come from various sources: &lt;em&gt;internal&lt;/em&gt; (microservices communication based on AMQP) and &lt;em&gt;external&lt;/em&gt; (MQTT and STOMP, available for mobile apps, web apps, devices).&lt;/p&gt;

&lt;p&gt;As a matter of fact, if something goes wrong with the broker, all communications stop. And things can go wrong in a lot of ways: broker crash (not so often), massive reconnection event (thousands of devices reconnecting at the same time), or sudden spike of messages in a specific exchange (if consumers aren‚Äôt fast enough, messages will pile up and performance can degrade for all the system).&lt;/p&gt;

&lt;p&gt;Also, brokers exposing different protocols to various types of clients need to play with a lot of constraints: you need to tune for both throughput and high number of connections and you‚Äôre over-exposed to bugs due to the large number of plugins and custom settings you have to put in the game.&lt;/p&gt;

&lt;p&gt;Finally, if you open communication channels to partners or external developers, you can‚Äôt easily isolate environments (privisioning, security, compliance, ‚Ä¶) and probability of occurrence of a problem increases dramatically (for instance with bugs from incorrectly coded firmware), and you‚Äôre rapidly stuck with inextricable compatibility or upgrade issues (like impossibility to server different protocol versions to different clients).&lt;/p&gt;

&lt;p&gt;Taking into account the experience we grew with RabbitMQ, and the large set of topologies you can build with it, it was a valid choice for us to help us build our next messaging system.&lt;/p&gt;

&lt;h3 id=&quot;splitting-brokers&quot;&gt;Splitting brokers&lt;/h3&gt;

&lt;p&gt;The plan was then to split the broker (actually cluster of brokers but we‚Äôre refering to it as a single entity). The plan was to create a &lt;em&gt;backend&lt;/em&gt; cluster to keep backend communications completely internal and expose external channels through &lt;em&gt;gateway&lt;/em&gt; brokers that could be located in different places of the world. But those brokers would have to send messages to each others (between backend and each gateway, not between gateways).&lt;/p&gt;

&lt;p&gt;To do that, RabbitMQ has 2 plugins called &lt;a href=&quot;https://www.rabbitmq.com/federation.html&quot;&gt;federation&lt;/a&gt; and &lt;a href=&quot;https://www.rabbitmq.com/shovel.html&quot;&gt;shovel&lt;/a&gt;. Deciding which one to pick depends on target topology, patterns of message transfer and level of control you need.&lt;/p&gt;

&lt;p&gt;We rolled out the plan in several phases, but are the 2 major steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;1 backend cluster + 1 gateway cluster&lt;/strong&gt; with direct messages routing through federation. Below a logical representation of how they communicate:
&lt;img src=&quot;https://airboxlab.github.io//assets/scale_mqtt/rabbitmq_split_step1.png&quot; alt=&quot;step 1&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;1 backend cluster + X gateway clusters&lt;/strong&gt; with &lt;em&gt;intelligent&lt;/em&gt; routing: when messages need to be routed to more than 1 gateway, it becomes inefficient to send all messages to all gateways. We developped a simple message router that route messages based on known location of the client (and broadcasts in case of doubt).
&lt;img src=&quot;https://airboxlab.github.io//assets/scale_mqtt/rabbitmq_split_step2.png&quot; alt=&quot;step 2&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Clients are routed using AWS Route53 latency-based configuration.&lt;/p&gt;

&lt;h3 id=&quot;tuning-rabbitmq&quot;&gt;Tuning RabbitMQ&lt;/h3&gt;

&lt;p&gt;It‚Äôs possible to tune RabbitMQ for throughput or for large number of connections. This is well documented &lt;a href=&quot;https://www.rabbitmq.com/networking.html&quot;&gt;here&lt;/a&gt;. We naturally applied those recommendations in order to maximize throughput on the backend cluster, and increase capacity to handle large number of connections on gateways.&lt;/p&gt;

&lt;p&gt;We have also enabled HiPE compilation to increase throughput on some clusters and this is giving excellent results.&lt;/p&gt;

&lt;p&gt;Running on AWS, we chose the ‚Äòc‚Äô type for our instances: RabbitMQ can be CPU intensive, for throughput intensive workloads, or when connections churn is high (which happens quite often if you have clients connecting from everywhere). We favored c3 instances (cheaper storage with SSD instance store volumes - requires snapshots for instance crash recovery) but c4 with proper IOPS configuration (gp2 or io1) does the trick (more expansive but data survives server crash or restart).&lt;/p&gt;

&lt;h3 id=&quot;repeatability&quot;&gt;Repeatability&lt;/h3&gt;

&lt;p&gt;The way we decide to deploy and locate gateways is data-driven: we do it depending on current number of customers per region/country, forecast in sells, new projects, and technical factors. Once we are aware of those parameters, it‚Äôs important to make the operation of setting up a new gateway as automatic as possible.&lt;/p&gt;

&lt;p&gt;Of course, spinning up a new gateway isn‚Äôt just a matter of 1 new server in an AWS region: we have to setup the VPC, VPN connection with backend, proxy servers, and other IT support instances.&lt;/p&gt;

&lt;p&gt;We did it using Hashicorp Terraform: it lets you declare and interact with AWS resources from declaration in simple configuration files. Almost all AWS resources are available, see &lt;a href=&quot;https://www.terraform.io/docs/providers/aws/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now if need to spawn a new gateway, it‚Äôs a matter of hours.&lt;/p&gt;

&lt;h2 id=&quot;where-we-are-now&quot;&gt;Where we are now&lt;/h2&gt;

&lt;p&gt;We started deploying these solutions in productions in March, and now we have 2 gateways in production (US and Japan), handling tens of thousands of connections.&lt;/p&gt;

&lt;p&gt;Scalability and resiliency improved, and we significantly reduced number of problems we used to have. Also, massive reconnections are much less massive, by design: fewer clients per node, and clients are geographically closer to brokers, which reduces risk of network hicups.&lt;/p&gt;

&lt;p&gt;We also improved maintainability: upgrades are progressively applied accross clusters, and we aren‚Äôt tied to a single solution anymore: if we decide to go for another messaging implementation for a particular need, it will be much easier to plug in.&lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next steps&lt;/h3&gt;

&lt;p&gt;We want to achieve strong high availability, using AWS Route53 latency + health checks based routing. This will answer the question ‚Äúwhat happens if the entire cluster of brokers is down?‚Äù. A good example can be found &lt;a href=&quot;http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Split, split again! Internal workloads handled by the core cluster can be further segragated, by sending messages to dedicated message brokers, where relevant. Specifically, some of our workloads are log-oriented, don‚Äôt need true real-time processing, and would benefit from several days of data retention. Using something like kafka or kinesis would help in that matter.&lt;/p&gt;

</description>
        <pubDate>Tue, 27 Jun 2017 06:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//iot/mqtt/scalability/rabbitmq/2017/06/27/scaling_mqtt.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//iot/mqtt/scalability/rabbitmq/2017/06/27/scaling_mqtt.html</guid>
        
        
        <category>iot</category>
        
        <category>mqtt</category>
        
        <category>scalability</category>
        
        <category>rabbitmq</category>
        
      </item>
    
      <item>
        <title>Tuning Quartz Scheduler for large number of small jobs</title>
        <description>&lt;h2 id=&quot;what-we-do-with-quartz-scheduler&quot;&gt;What we do with Quartz Scheduler&lt;/h2&gt;

&lt;p&gt;We used &lt;a href=&quot;http://www.quartz-scheduler.org/&quot;&gt;Quartz Scheduler&lt;/a&gt; in first place to schedule time-based events on a large number of our HVAC devices, in order to trigger changes from one mode to another, and define interactions between modes. We then extended usage of Quartz to different areas, but the main usage pattern remains to run short-lived jobs that perform a single action.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;Quoted from Quartz documentation: ‚Äú&lt;em&gt;The clustering feature works best for scaling out long-running and/or cpu-intensive jobs (distributing the work-load over multiple nodes). If you need to scale out to support thousands of short-running (e.g 1 second) jobs, consider partitioning the set of jobs by using multiple distinct schedulers (including multiple clustered schedulers for HA). The scheduler makes use of a cluster-wide lock, a pattern that degrades performance as you add more nodes (when going beyond about three nodes - depending upon your database‚Äôs capabilities, etc.).&lt;/em&gt;‚Äù&lt;/p&gt;

&lt;p&gt;Indeed, it‚Äôs easy to confirm that adding nodes to a cluster doesn‚Äôt improve things at all (tested with 4, 5 and 6 nodes).&lt;/p&gt;

&lt;p&gt;Cluster-wide lock is obtained by the &lt;code&gt;QuartzSchedulerThread&lt;/code&gt; using a database lock (&lt;code&gt;SELECT ... FOR UPDATE&lt;/code&gt;). It ‚Äúreserves‚Äù a certain amount of triggers to execute (amount decided by &lt;code&gt;org.quartz.scheduler.batchTriggerAcquisitionMaxCount&lt;/code&gt;), execute them (in parallel, number of worker threads can be configured using &lt;code&gt;org.quartz.threadPool.threadCount&lt;/code&gt;, should be equal to batchTriggerAcquisitionMaxCount), then release the lock.&lt;/p&gt;

&lt;p&gt;What happens in reality, for a clustered scheduler, is that one instance will execute the desired number of triggers while the other will be doing nothing. Clustering in Quarz is for high availability, or for load-balancing long-running jobs, but as stated in the docs, doesn‚Äôt help to run high number of short-lived jobs.&lt;/p&gt;

&lt;p&gt;The impact for our clients was directly visible: instead of seeing desired action triggered a few seconds after desired time, it could take several minutes before kicking in. This can be illustrated by below chart:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io//assets/scale_quartz/schedulerlab_14_00_06_06_2017.png&quot; alt=&quot;before sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, a large part of our end users chose to trigger events on their devices at very common times (top of hour), so we need to handle a huge burst in the number of jobs to execute at specific hours of the day.&lt;/p&gt;

&lt;h2 id=&quot;sharding-to-the-rescue&quot;&gt;Sharding to the rescue&lt;/h2&gt;

&lt;p&gt;Jobs sharding isn‚Äôt a feature proposed by Quartz, although database structure is ready for that. As proposed in the documentation, the idea is to spawn different scheduler instances, each one responsible for a set of shards.&lt;/p&gt;

&lt;p&gt;Sharding can be done in different manners: creating meaningful shards (product category, company, ‚Ä¶) or using hashing based on some key (device UUID, user ID, ‚Ä¶). We choose the latest, as it offers best sharding capabilities (no risk to create ‚Äúfat‚Äù shards) and our jobs were already stored with these IDs.&lt;/p&gt;

&lt;p&gt;To ensure sharding will remain efficient in time, especially during re-sharding operations (adding/removing new scheduler instance), it was important to use consistent hashing: using the simple hashing approach &lt;em&gt;hash(k) mod n&lt;/em&gt;, any change of &lt;em&gt;n&lt;/em&gt; will require to move a large number of keys, which can degrade performance a lot during operation. Instead, it‚Äôs preferable to use a consistent hashing technique: a ‚Äúring‚Äù of virtual shards is created first and each node is responsible for a set of partitions. Adding a new node requires to move only &lt;em&gt;1/(n+1)&lt;/em&gt; keys to the new node (scheduler). If number of keys remain equal, time for resharding decreases when number of nodes increases.&lt;/p&gt;

&lt;p&gt;In our case, re-sharding involves updating jobs, triggers and related definitions in DB, so the less time it takes, the better. Here is a small benchmark that illustrates time it takes to move keys (update tables) with the 2 hashing techniques:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Re-sharding after node addition benchmark (local MySQL, 8800 keys)&lt;/em&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;nb shards&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;naive hashing&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;consistent hashing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4400 keys moved / 360 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4290 keys moved / 349 sec&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4800 keys moved / 460 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2440 keys moved / 190 sec&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5500 keys moved / 570 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1820 keys moved / 145 sec&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This consistent hashing mechanism has then to be made available to our scheduler API clients, so they can pick the right scheduler instance. To do that, each scheduler registers in our service discovery tool with a custom attribute (we use Consul, so the service registers with a custom tag) that represents its node ID. Then, each client discovers the service using the tag computed from hashing job key.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io//assets/scale_quartz/scheduler_sharding.png&quot; alt=&quot;sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In above diagram we see multiple MySQL databases, which is a possible solution for further increasing throughput (although not tested). On our side, we still use the same table structures to store all schedulers data.&lt;/p&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;p&gt;Here we‚Äôre presenting results from up to 4 schedulers: with more, we faced bottlenecks in downstream processes (benchmarks were done with ‚Äúreal-life‚Äù jobs), and we hit the limits of the instance we were running the jobs on (&amp;gt; 90% CPU usage). With 8 schedulers, and if all downstream communications are disabled, we reached &lt;strong&gt;1350 jobs/sec&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io//assets/scale_quartz/benchmark.png&quot; alt=&quot;benchmark&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;deploying-in-production&quot;&gt;Deploying in production&lt;/h2&gt;

&lt;p&gt;We deployed 3 distinct scheduler instances in our target datacenter. Deployment took the scheduler API down for 4 minutes while resharding operation was in progress. The operation is triggered automatically by the service, if it‚Äôs configured with a node ID that has no associated job in database. Adding a new scheduler is automatic and doesn‚Äôt require any additional configuration.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io//assets/scale_quartz/schedulerlab_14_00_12_06_2017.png&quot; alt=&quot;after sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jobs at this hour now execute within an acceptable time, and most importantly we are confident we can now handle much more and keep execution times low.&lt;/p&gt;
</description>
        <pubDate>Tue, 20 Jun 2017 10:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//performance/scalability/scheduler/quartz/2017/06/20/perf_tuning_quartz.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//performance/scalability/scheduler/quartz/2017/06/20/perf_tuning_quartz.html</guid>
        
        
        <category>performance</category>
        
        <category>scalability</category>
        
        <category>scheduler</category>
        
        <category>quartz</category>
        
      </item>
    
      <item>
        <title>A streaming pipeline for the IoT with Apache Spark &amp; microservices</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.callout {
    float: right;
    margin-left: 5px;
}
&lt;/style&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/data_pipeline/oilpipeline.jpg&quot; alt=&quot;oil pipeline&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-is-airboxlab-doing-with-foobot-data&quot;&gt;What is Airboxlab doing with Foobot data?&lt;/h2&gt;

&lt;p&gt;We build Foobot, which sends indoor air quality data on a regular schedule. This data represents our users most valuable information, and is why they are buying a Foobot for. 
This data itself is the core of our business, and as engineers we have to secure the process of receiving and storing it.&lt;/p&gt;

&lt;p&gt;However, data alone isn‚Äôt enough to give users a smart and complete experience so they can learn and act to improve their environment: an important part of the value is in the processing of this data, how we react to it, and at what speed. 
Indoor air quality is a matter of comfort and health, hence being alerted too late that the air you breath is polluted reduces interest and impact of the product a lot. In a similar manner, if you used a toxic cleanser but your ventilation system kicks in too late you just bought a mute doctor: he knows what you‚Äôre suffering from but can‚Äôt help!&lt;/p&gt;

&lt;p&gt;That‚Äôs why engineers at Airboxlab invest a lot in building a reliable, scalable and extensible streaming data pipeline. We want to make sure data is safe, that we react appriopriately and in a timely fashion to it, and that the next useful external system integration (be it a thermostat, HVAC system, IFTTT-like platform, customized stream‚Ä¶) will be straightforward.&lt;/p&gt;

&lt;h2 id=&quot;anatomy-of-our-streaming-pipeline&quot;&gt;Anatomy of our streaming pipeline&lt;/h2&gt;

&lt;h3 id=&quot;sources-sinks--jobs&quot;&gt;Sources, Sinks &amp;amp; Jobs&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Sources&lt;/strong&gt; in our pipelines are various. Most data (in volume) is emitted by Foobot sensors, but there are also events sent by applications (mobile, web), internal sources of static data (for instance device or user definitions that can serve to enrich context), and intermediate results in the pipeline that can be served as sources in other steps.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sinks&lt;/strong&gt; are also of various nature. We can categorize them as following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;persistent storage, like SQL and NoSQL databases, HDFS and S3&lt;/li&gt;
  &lt;li&gt;transient like message brokers to which analysis from processed input are sent on structured topics. Downstream pipeline clients subscribe to the topics they are interested in, process incoming messages, and send results to another sink&lt;/li&gt;
  &lt;li&gt;external like external API offered by partners&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Jobs&lt;/strong&gt; are the processes that transform input from a source to a desired result and output it to a sink. We have 2 types: &lt;em&gt;Spark Streaming&lt;/em&gt; jobs and &lt;em&gt;microservices&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt; between sources, sinks &amp;amp; jobs depends on physical location of them (e.g. Foobot devices are living in users networks, data is sent through WAN), performance requirements (in memory vs over network), and flexibility (need to start/stop a source/sink dynamically).&lt;/p&gt;

&lt;p&gt;Finally, a streaming pipeline is all about sources, sinks and how data goes from one to another. With (you guess so) complex interactions between them. That‚Äôs what I‚Äôm going to detail in the next section.&lt;/p&gt;

&lt;h3 id=&quot;sensor-data-streaming-pipeline&quot;&gt;Sensor data streaming pipeline&lt;/h3&gt;

&lt;p&gt;This is our main data pipeline, the richer and more complex one (there are also other peripheral pipelines that fulfill specific requirements). We can summarize its functions as following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ingestion&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/data_pipeline/data_pipeline_ingestion.png&quot; alt=&quot;ingestion&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Between sensor data emission and storage the path must be as short as possible. The shorter it is, the less we expose ourselves to failure and eventually data loss. Hence storage happens right away after reception. Job responsible for receiving and storing is extremely simple, load-balanced, and tolerant to failure.&lt;/p&gt;

        &lt;p&gt;Also, we don‚Äôt throw anything, even ‚Äújunk‚Äù data that can sometimes be sent during temporary or permanent failure of a sensor: this won‚Äôt be taken into account by downstream consumers of the main pipeline but is used for failure detection.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Transformation&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Sensor data is sent in a specific, raw, compressed format in order to save bandwidth. This step transforms this data into a json document. It also performs input validation in the meantime.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Contextual enrichment&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Raw sensor data is stored but not used as is downstream: we need to calibrate them in order to have meaningful values. Each device has its own calibration (each sensor is slightly different). Device-specific static data is also added to the context, and the whole forms the first rich json document that is sent to multiple downstream consumers.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Aggregations &amp;amp; statistics computing&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Stats&lt;/strong&gt; are continuously computed for each device connected to our backend. Most of them are quite basic, like cumulative moving averages for each sensor, some others are based on regressions, like averages of top minimum or maximum values.&lt;/p&gt;

    &lt;p&gt;Most statistics computations never imply loading historical values: this would be a scaling problem. Whenever possible, we use a rolling/cumulative version of the statistic.&lt;/p&gt;

    &lt;p&gt;Statistics are used by several consumers:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;calibration adapter that is used to adapt sensors baseline&lt;/li&gt;
      &lt;li&gt;other jobs in the pipeline that can trigger events based on statictics values&lt;/li&gt;
      &lt;li&gt;reporting tools, for instance one that email a periodic email to users telling him how was air quality in the past days or weeks&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;We also perform &lt;strong&gt;aggregations&lt;/strong&gt; that are used downstream or served to users (values available by API, used by mobile and web apps). It reduces average response size and latency.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Alerting&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/data_pipeline/data_pipeline_alerting.png&quot; alt=&quot;ingestion&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Alerting is the process of raising an alert when a particular event occurs. That is often related to a sensor data value crossing a standard or user-defined threshold, what we call instant threshold crossing, but can be more complex when it comes to ‚Äúair quality event‚Äù detection. A simple type of event would be a pollution event, one that starts when a pollutant crosses a threshold and ends when it comes back to normal. This implies using mechanisms like windowing and stateful operations to preserve event state, or applying hysteresis for values constantly crossing thresholds up and down.&lt;/p&gt;

    &lt;p&gt;There are 2 main types of consumers to these alerts:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Direct user notifiers, mostly using mobile push notifications&lt;/li&gt;
      &lt;li&gt;External systems notifications: for instance we can trigger the ventilation system linked to an Ecobee thermostat if particulate matter level is higher than user-defined threshold.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Machine learning&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;We apply machine learning at various levels, from calibration baseline improvement to air quality events detection. We use algorithm implementations provided by Spark ML that can be integrated in Spark Streaming jobs: here Spark reveals all its power, as all these bricks feet well together.
Downstream consumers are somehow the same as for alerting.&lt;/p&gt;

    &lt;p&gt;There are things to say here, but we‚Äôll cover this in a future blog post.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backup&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/data_pipeline/data_pipeline_backup.png&quot; alt=&quot;ingestion&quot; class=&quot;callout&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Even backup can be done in a near real-time manner: instead of fetching and storing data in an external backup store on a daily basis, why not benefit from streaming pipeline to do it at event processing time. This is how we implemented our incremental and asynchronous backup system. This has several advantages:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;2 seat belts: data is stored on arrival, and almost immediately backed up.&lt;/li&gt;
      &lt;li&gt;we can develop alternative pipelines to handle temporary or non mission critical tools: we store backup data in HDFS, that can be a source for &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html#basic-sources&quot;&gt;Spark Streaming&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;we have an up-to-date offline version of our data on which we can perform heavy data mining and model training.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;keeping-the-pipeline-flexible&quot;&gt;Keeping the pipeline flexible&lt;/h2&gt;

&lt;p&gt;The backbone of our pipeline relies on Spark Streaming, which allows us to dedicate more or less resources (CPU &amp;amp; RAM) to streaming jobs, making it able to scale well. Dividing each functional process into separate jobs allows us to re-deploy or scale them independently.&lt;/p&gt;

&lt;p&gt;An other important thing in our day-to-day job is to be able to ‚Äúplug‚Äù a new job at the ‚Äúperiphery‚Äù of the pipeline quickly. For instance, we often decide to interact with a new external vendor API, and we don‚Äôt want to think about anything else than:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what will the service subscribe to?&lt;/li&gt;
  &lt;li&gt;how will it interact with the API?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most importantly, we want to avoid modifying other jobs in the pipeline as much as possible. This allows us to develop and deploy the new service without restarting anything else.&lt;/p&gt;

&lt;p&gt;On another hand, we want subscriptions to be dynamic too. For instance, a new user connects on IFTTT and wants its &lt;a href=&quot;https://ifttt.com/connect/foobot/wemo_switch&quot;&gt;Foobot to turn on his WeMo switch&lt;/a&gt;  whenever global pollution level is too bad. To do that, we will record user configuration but also make the service responsible for interacting with IFTTT listen to relevant user‚Äôs device events. 
Similarly, if user disconnects from Foobot channel, we don‚Äôt want the service keep listening to his thresholds alerts.&lt;/p&gt;

&lt;p&gt;In order to fulfill these requirements, we opted for a &lt;strong&gt;microservices&lt;/strong&gt; architecture very early. This brings the following benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;easier to develop a new service&lt;/em&gt;: we invested a bit in simplifying services creation, so creating a new one is a matter of minutes.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to extends a service functionality&lt;/em&gt;: let‚Äôs say you want to add a trigger to your IFTTT channel: you‚Äôll only need to change this service code, and retest it. Nothing else. This greatly reduces the risk of regression in other functionalities, and allows us to deploy faster and more often&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;efficient communication&lt;/em&gt;: each service subscribes and reacts to the events it‚Äôs supposed to listen to. We structured messaging topics so that services receive only what they need.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to test&lt;/em&gt;: well, easier than having to deploy the whole pipeline and re-testing everything. Testing a pipeline is still harder than a classic piece of software though, so we invested in a internal testing microframework that helps writing integration tests.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to scale&lt;/em&gt; a particular integration: one of our integration becomes popular? we can spin up new services only for this type, making the whole architecture cost-efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://airboxlab.github.io/assets/data_pipeline/data_pipeline_subscribers.png&quot; alt=&quot;subscribers&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This article gave an overview of one of the most critical part of our system, and explains why we choose Spark Streaming and microservices to implement it. 
A future series of articles will dive into more specific parts of the pipeline.&lt;/p&gt;

</description>
        <pubDate>Mon, 29 Aug 2016 14:00:00 +0200</pubDate>
        <link>https://airboxlab.github.io//streaming/microservices/iot/spark/real-time/2016/08/29/streaming-microservices.html</link>
        <guid isPermaLink="true">https://airboxlab.github.io//streaming/microservices/iot/spark/real-time/2016/08/29/streaming-microservices.html</guid>
        
        
        <category>streaming</category>
        
        <category>microservices</category>
        
        <category>iot</category>
        
        <category>spark</category>
        
        <category>real-time</category>
        
      </item>
    
  </channel>
</rss>

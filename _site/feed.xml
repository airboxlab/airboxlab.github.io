<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Airboxlab Technical Blog</title>
    <description>The guys behind Foobot.Talking here about our achievements, failures &amp; OSS contributions
</description>
    <link>http://0.0.0.0:4000/</link>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 20 Jun 2017 14:23:17 +0200</pubDate>
    <lastBuildDate>Tue, 20 Jun 2017 14:23:17 +0200</lastBuildDate>
    <generator>Jekyll v3.3.1</generator>
    
      <item>
        <title>Tuning Quartz Scheduler for large number of small jobs</title>
        <description>&lt;h2 id=&quot;what-we-do-with-quartz-scheduler&quot;&gt;What we do with Quartz Scheduler&lt;/h2&gt;

&lt;p&gt;We used &lt;a href=&quot;http://www.quartz-scheduler.org/&quot;&gt;Quartz Scheduler&lt;/a&gt; in first place to schedule time-based events on a large number of our HVAC devices, in order to trigger changes from one mode to another, and define interactions between modes. We then extended usage of Quartz to different areas, but the main usage pattern remains to run short-lived jobs that perform a single action.&lt;/p&gt;

&lt;h2 id=&quot;the-problem&quot;&gt;The problem&lt;/h2&gt;

&lt;p&gt;Quoted from Quartz documentation: “&lt;em&gt;The clustering feature works best for scaling out long-running and/or cpu-intensive jobs (distributing the work-load over multiple nodes). If you need to scale out to support thousands of short-running (e.g 1 second) jobs, consider partitioning the set of jobs by using multiple distinct schedulers (including multiple clustered schedulers for HA). The scheduler makes use of a cluster-wide lock, a pattern that degrades performance as you add more nodes (when going beyond about three nodes - depending upon your database’s capabilities, etc.).&lt;/em&gt;”&lt;/p&gt;

&lt;p&gt;Indeed, it’s easy to confirm that adding nodes to a cluster doesn’t improve things at all (tested with 4, 5 and 6 nodes).&lt;/p&gt;

&lt;p&gt;Cluster-wide lock is obtained by the &lt;code&gt;QuartzSchedulerThread&lt;/code&gt; using a database lock (&lt;code&gt;SELECT ... FOR UPDATE&lt;/code&gt;). It “reserves” a certain amount of triggers to execute (amount decided by &lt;code&gt;org.quartz.scheduler.batchTriggerAcquisitionMaxCount&lt;/code&gt;), execute them (in parallel, number of worker threads can be configured using &lt;code&gt;org.quartz.threadPool.threadCount&lt;/code&gt;, should be equal to batchTriggerAcquisitionMaxCount), then release the lock.&lt;/p&gt;

&lt;p&gt;What happens in reality, for a clustered scheduler, is that one instance will execute the desired number of triggers while the other will be doing nothing. Clustering in Quarz is for high availability, or for load-balancing long-running jobs, but as stated in the docs, doesn’t help to run high number of short-lived jobs.&lt;/p&gt;

&lt;p&gt;The impact for our clients was directly visible: instead of seeing desired action triggered a few seconds after desired time, it could take several minutes before kicking in. This can be illustrated by below chart:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_quartz/schedulerlab_14_00_06_06_2017.png&quot; alt=&quot;before sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As you can see, a large part of our end users chose to trigger events on their devices at very common times (top of hour), so we need to handle a huge burst in the number of jobs to execute at specific hours of the day.&lt;/p&gt;

&lt;h2 id=&quot;sharding-to-the-rescue&quot;&gt;Sharding to the rescue&lt;/h2&gt;

&lt;p&gt;Jobs sharding isn’t a feature proposed by Quartz, although database structure is ready for that. As proposed in the documentation, the idea is to spawn different scheduler instances, each one responsible for a set of shards.&lt;/p&gt;

&lt;p&gt;Sharding can be done in different manners: creating meaningful shards (product category, company, …) or using hashing based on some key (device UUID, user ID, …). We choose the latest, as it offers best sharding capabilities (no risk to create “fat” shards) and our jobs were already stored with these IDs.&lt;/p&gt;

&lt;p&gt;To ensure sharding will remain efficient in time, especially during re-sharding operations (adding/removing new scheduler instance), it was important to use consistent hashing: using the simple hashing approach &lt;em&gt;hash(k) mod n&lt;/em&gt;, any change of &lt;em&gt;n&lt;/em&gt; will require to move a large number of keys, which can degrade performance a lot during operation. Instead, it’s preferable to use a consistent hashing technique: a “ring” of virtual shards is created first and each node is responsible for a set of partitions. Adding a new node requires to move only &lt;em&gt;1/(n+1)&lt;/em&gt; keys to the new node (scheduler). If number of keys remain equal, time for resharding decreases when number of nodes increases.&lt;/p&gt;

&lt;p&gt;In our case, re-sharding involves updating jobs, triggers and related definitions in DB, so the less time it takes, the better. Here is a small benchmark that illustrates time it takes to move keys (update tables) with the 2 hashing techniques:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Re-sharding after node addition benchmark (local MySQL, 8800 keys)&lt;/em&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;nb shards&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;naive hashing&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;consistent hashing&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4400 keys moved / 360 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4290 keys moved / 349 sec&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4800 keys moved / 460 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2440 keys moved / 190 sec&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5500 keys moved / 570 sec&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1820 keys moved / 145 sec&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;This consistent hashing mechanism has then to be made available to our scheduler API clients, so they can pick the right scheduler instance. To do that, each scheduler registers in our service discovery tool with a custom attribute (we use Consul, so the service registers with a custom tag) that represents its node ID. Then, each client discovers the service using the tag computed from hashing job key.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_quartz/scheduler_sharding.png&quot; alt=&quot;sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In above diagram we see multiple MySQL databases, which is a possible solution for further increasing throughput (although not tested). On our side, we still use the same table structures to store all schedulers data.&lt;/p&gt;

&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;

&lt;p&gt;Here we’re presenting results from up to 4 schedulers: with more, we faced bottlenecks in downstream processes (benchmarks were done with “real-life” jobs), and we hit the limits of the instance we were running the jobs on (&amp;gt; 90% CPU usage). With 8 schedulers, and if all downstream communications are disabled, we reached &lt;strong&gt;1350 jobs/sec&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_quartz/benchmark.png&quot; alt=&quot;benchmark&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;deploying-in-production&quot;&gt;Deploying in production&lt;/h2&gt;

&lt;p&gt;We deployed 3 distinct scheduler instances in our target datacenter. Deployment took the scheduler API down for 4 minutes while resharding operation was in progress. The operation is triggered automatically by the service, if it’s configured with a node ID that has no associated job in database. Adding a new scheduler is automatic and doesn’t require any additional configuration.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_quartz/schedulerlab_14_00_12_06_2017.png&quot; alt=&quot;after sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jobs at this hour now execute within an acceptable time, and most importantly we are confident we can now handle much more and keep execution times low.&lt;/p&gt;
</description>
        <pubDate>Tue, 20 Jun 2017 10:00:00 +0200</pubDate>
        <link>http://0.0.0.0:4000/performance/scalability/scheduler/quartz/2017/06/20/perf_tuning_quartz.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/performance/scalability/scheduler/quartz/2017/06/20/perf_tuning_quartz.html</guid>
        
        
        <category>performance</category>
        
        <category>scalability</category>
        
        <category>scheduler</category>
        
        <category>quartz</category>
        
      </item>
    
      <item>
        <title>Scaling MQTT connections with RabbitMQ</title>
        <description>&lt;h2 id=&quot;suddenly-it-failed&quot;&gt;Suddenly, it failed&lt;/h2&gt;

&lt;p&gt;It happened at the beginning of 2017. Our number of clients had grown steadily so far, and we were confident our current MQTT clusters configuration was strong enough to cope with it for a while.&lt;/p&gt;

&lt;p&gt;Wrong! So wrong! While we were quietly preparing for weekend leave, several alarm bells rang: rabbitmq node 1 not responding, then another, finally the entire cluster. Ok, no worries, let’s just restart it. Wrong again! While it’s easy to change a tire on a stopped car, doing it when you’re driving at 200 km/h is another thing: clients trying to automatically reconnect were preventing a smooth restart. After several unsuccessful attempts, lot of sweat, and placing the cluster in a safe mode, we finally managed to get it back to work.&lt;/p&gt;

&lt;h2 id=&quot;after-the-storm-time-to-look-back&quot;&gt;After the storm, time to look back&lt;/h2&gt;

&lt;p&gt;With this painful event, we realized we were still operating our message brokers, and everything around, as if they were handling a few hundreds of clients. Although we knew we would have to strengthen this core part of our infrastructure, it wasn’t showing any sign of weakness. The danger of things working well is you quickly forget them! And in a small but rapidly growing shop like ours, priorities change. Still, reality strikes back to make you face all the things you are missing:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;strong isolation&lt;/strong&gt;: a single message brokers cluster that does everything (internal/external communication) is very convenient at the beginning: it’s cheap and easy to setup. But one piece failing and the entire system is out. Also, upgrading or simply tuning becomes a stressful operation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;performance tests&lt;/strong&gt;: what are our needs if number of clients double? Are we able to deal with forecasted throughput? What happens under flaky network conditions? What harwdware for that?&lt;/li&gt;
  &lt;li&gt;clear &lt;strong&gt;disaster recovery procedures&lt;/strong&gt;: a document with some basic steps isn’t enough. Let’s learn from disasters, and shape up a correct recovery plan with realistic scenarios and steps.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This article focuses on 1st point (but we worked also on the others, performance tests were one of the prerequisites for developing the solution).&lt;/p&gt;

&lt;h2 id=&quot;divide-and-conquer&quot;&gt;Divide and conquer&lt;/h2&gt;

&lt;p&gt;We expose our services through different APIs and protocols, but most of the activity comes from asynchronous messages processing that come from various sources: &lt;em&gt;internal&lt;/em&gt; (microservices communication based on AMQP) and &lt;em&gt;external&lt;/em&gt; (MQTT and STOMP, available for mobile apps, web apps, devices).&lt;/p&gt;

&lt;p&gt;As a matter of fact, if something goes wrong with the broker, all communications stop. And things can go wrong in a lot of ways: broker crash (not so often), massive reconnection event (thousands of devices reconnecting at the same time), or sudden spike of messages in a specific exchange (if consumers aren’t fast enough, messages will pile up and performance can degrade for all the system).&lt;/p&gt;

&lt;p&gt;Also, brokers exposing different protocols to various types of clients need to play with a lot of constraints: you need to tune for both throughput and high number of connections and you’re over-exposed to bugs due to the large number of plugins and custom settings you have to put in the game.&lt;/p&gt;

&lt;p&gt;Finally, if you open communication channels to partners or external developers, you can’t easily isolate environments (privisioning, security, compliance, …) and probability of occurrence of a problem increases dramatically (for instance with bugs from incorrectly coded firmware), and you’re rapidly stuck with inextricable compatibility or upgrade issues (like impossibility to server different protocol versions to different clients).&lt;/p&gt;

&lt;p&gt;Taking into account the experience we grew with RabbitMQ, and the large set of topologies you can build with it, it was a valid choice for us to help us build our next messaging system.&lt;/p&gt;

&lt;h3 id=&quot;splitting-brokers&quot;&gt;Splitting brokers&lt;/h3&gt;

&lt;p&gt;The plan was then to split the broker (actually cluster of brokers but we’re refering to it as a single entity). The plan was to create a &lt;em&gt;backend&lt;/em&gt; cluster to keep backend communications completely internal and expose external channels through &lt;em&gt;gateway&lt;/em&gt; brokers that could be located in different places of the world. But those brokers would have to send messages to each others (between backend and each gateway, not between gateways).&lt;/p&gt;

&lt;p&gt;To do that, RabbitMQ has 2 plugins called &lt;a href=&quot;https://www.rabbitmq.com/federation.html&quot;&gt;federation&lt;/a&gt; and &lt;a href=&quot;https://www.rabbitmq.com/shovel.html&quot;&gt;shovel&lt;/a&gt;. Deciding which one to pick depends on target topology, patterns of message transfer and level of control you need.&lt;/p&gt;

&lt;p&gt;We rolled out the plan in several phases, but are the 2 major steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;1 backend cluster + 1 gateway cluster&lt;/strong&gt; with direct messages routing through federation. Below a logical representation of how they communicate:
&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_mqtt/rabbitmq_split_step1.png&quot; alt=&quot;step 1&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;1 backend cluster + X gateway clusters&lt;/strong&gt; with &lt;em&gt;intelligent&lt;/em&gt; routing: when messages need to be routed to more than 1 gateway, it becomes inefficient to send all messages to all gateways. We developped a simple message router that route messages based on known location of the client (and broadcasts in case of doubt).
&lt;img src=&quot;http://0.0.0.0:4000/assets/scale_mqtt/rabbitmq_split_step2.png&quot; alt=&quot;step 2&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Clients are routed using AWS Route53 latency-based configuration.&lt;/p&gt;

&lt;h3 id=&quot;tuning-rabbitmq&quot;&gt;Tuning RabbitMQ&lt;/h3&gt;

&lt;p&gt;It’s possible to tune RabbitMQ for throughput or for large number of connections. This is well documented &lt;a href=&quot;https://www.rabbitmq.com/networking.html&quot;&gt;here&lt;/a&gt;. We naturally applied those recommendations in order to maximize throughput on the backend cluster, and increase capacity to handle large number of connections on gateways.&lt;/p&gt;

&lt;p&gt;We have also enabled HiPE compilation to increase throughput on some clusters and this is giving excellent results.&lt;/p&gt;

&lt;p&gt;Running on AWS, we chose the ‘c’ type for our instances: RabbitMQ can be CPU intensive, for throughput intensive workloads, or when connections churn is high (which happens quite often if you have clients connecting from everywhere). We favored c3 instances (cheaper storage with SSD instance store volumes - requires snapshots for instance crash recovery) but c4 with proper IOPS configuration (gp2 or io1) does the trick (more expansive but data survives server crash or restart).&lt;/p&gt;

&lt;h3 id=&quot;repeatability&quot;&gt;Repeatability&lt;/h3&gt;

&lt;p&gt;The way we decide to deploy and locate gateways is data-driven: we do it depending on current number of customers per region/country, forecast in sells, new projects, and technical factors. Once we are aware of those parameters, it’s important to make the operation of setting up a new gateway as automatic as possible.&lt;/p&gt;

&lt;p&gt;Of course, spinning up a new gateway isn’t just a matter of 1 new server in an AWS region: we have to setup the VPC, VPN connection with backend, proxy servers, and other IT support instances.&lt;/p&gt;

&lt;p&gt;We did it using Hashicorp Terraform: it lets you declare and interact with AWS resources from declaration in simple configuration files. Almost all AWS resources are available, see &lt;a href=&quot;https://www.terraform.io/docs/providers/aws/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now if need to spawn a new gateway, it’s a matter of hours.&lt;/p&gt;

&lt;h2 id=&quot;where-we-are-now&quot;&gt;Where we are now&lt;/h2&gt;

&lt;p&gt;We started deploying these solutions in productions in March, and now we have 2 gateways in production (US and Japan), handling tens of thousands of connections.&lt;/p&gt;

&lt;p&gt;Scalability and resiliency improved, and we significantly reduced number of problems we used to have. Also, massive reconnections are much less massive, by design: fewer clients per node, and clients are geographically closer to brokers, which reduces risk of network hicups.&lt;/p&gt;

&lt;p&gt;We also improved maintainability: upgrades are progressively applied accross clusters, and we aren’t tied to a single solution anymore: if we decide to go for another messaging implementation for a particular need, it will be much easier to plug in.&lt;/p&gt;

&lt;p&gt;Finally, we’ve seen new opportunities in this architecture: with repeatability of this solution, we can quickly offer our partners an isolated gateway to connect their clients.&lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next steps&lt;/h3&gt;

&lt;p&gt;We want to achieve strong high availability, using AWS Route53 latency + health checks based routing. This will answer the question “what happens if the entire cluster of brokers is down?”. A good example can be found &lt;a href=&quot;http://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-complex-configs.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Split, split again! Internal workloads handled by the core cluster can be further segragated, by sending messages to dedicated message brokers, where relevant. Specifically, some of our workloads are log-oriented, don’t need true real-time processing, and would benefit from several days of data retention. Using something like kafka or kinesis would help in that matter.&lt;/p&gt;

</description>
        <pubDate>Thu, 25 May 2017 10:00:00 +0200</pubDate>
        <link>http://0.0.0.0:4000/iot/mqtt/scalability/rabbitmq/2017/05/25/scaling_mqtt.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/iot/mqtt/scalability/rabbitmq/2017/05/25/scaling_mqtt.html</guid>
        
        
        <category>iot</category>
        
        <category>mqtt</category>
        
        <category>scalability</category>
        
        <category>rabbitmq</category>
        
      </item>
    
      <item>
        <title>Applying Machine Learning to Air Quality Events Analysis (Part I)</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.callout {
    float: right;
    margin-left: 5px;
    width: 200px;
}
&lt;/style&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/airqual_events_class/orion_nebula.jpg&quot; alt=&quot;orion galaxy?&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;Why was Dark Vador wearing a mask? When you hear him breathing, it’s obvious he had serious lung problems, at least severe asthma. Maybe he didn’t pay attention to Death Star indoor air quality enough. 
But who could blame? This was a huge space to monitor, with troopers coming and going all the time, cosmic dust from all galaxies, chemicals and exhaust gazes from spaceships…&lt;/p&gt;

&lt;p&gt;Indoor air quality can harm your internals, we know that. But if we aren’t able to know pollution sources, it gets tricky to avoid them; beyond taking basic actions when air quality degrades, it’d much more interesting to remove the source, change specific bad habits, automatically trigger the appropriate solution. It’s useful to trigger your ventilation every time VOC level is above a threshold, but what if you become aware that it comes from your house cleaning habbits?&lt;/p&gt;

&lt;p&gt;This is one of the subjects we’re working on at Airboxlab, and this article will be the first of a series of 2 describing how we decided to tackle the problem of pollution source awareness and the benefits it could bring. It also relates the mistakes we did along the way, and how we learned from them.&lt;/p&gt;

&lt;h2 id=&quot;first-approach-experiments-and-lessons-learned&quot;&gt;First approach: experiments and lessons learned&lt;/h2&gt;

&lt;p&gt;In the early days we were very enthusiastic: we’d have to monitor 1 or 2 houses for a while, ask users to note what they were doing (cooking, vacuum cleaning, …) while we were monitoring. Even better, we could get super accurate insight by installing extra sensors and monitors.&lt;/p&gt;

&lt;p&gt;When the experiment ended, we collected data and worked in collaboration with the &lt;a href=&quot;http://list.lu&quot;&gt;LIST&lt;/a&gt; to build our models. After a few weeks of work, conclusions came like a cold shower: no way to extract any significant pattern from collected data. Although graphs showed correlation between user activity and sensors response, no model could be built. Attempts to build classification models showed disappointing accuracy.&lt;/p&gt;

&lt;p&gt;However, this wasn’t a show stopper. We learned a lot from this first failed attempt.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;although accuracy was good and users carefully reported time there were doing things that could impact air quality, experiment was too short in time and data was scarse&lt;/li&gt;
  &lt;li&gt;dataset was imbalanced: some classes we wanted to learn about had no data at all&lt;/li&gt;
  &lt;li&gt;conducting experiment with different sensors, in a controlled environment, isn’t a portable approach. Our users wouldn’t be equipped the same way, and they obviously wouldn’t be that disciplined in reporting their actions. The resulting model wouldn’t match our users habits&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More importantly, we realized from last point that users were doing what we asked them. But our real users, the ones who bought our product and installed the app, would they try that hard to help us collect data? At that time, we weren’t able to ask them about causes because we weren’t telling them when &lt;em&gt;something&lt;/em&gt; happened. Solution at that time was to open the app, select a time range and select a catagory. Actually, some users were already doing it. But without any trigger, it was very hard to have a clue about what happened, when exactly, for how long, etc. Existing tags dataset collected from real users input was inaccurate and improper to learning.&lt;/p&gt;

&lt;p&gt;It became clear initial problem could be divided into 2 distinct ones:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;how can we detect air quality events?&lt;/li&gt;
  &lt;li&gt;how can we classify them?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And that would mean not a single model or pipeline to build, but several. First things first, we started to work on air quality events detection so we could notify users and ask them to tag air quality events.&lt;/p&gt;

&lt;h2 id=&quot;air-quality-events-an-approximate-definition&quot;&gt;Air quality events: an (approximate) definition&lt;/h2&gt;

&lt;p&gt;This first unsuccessful attempt to give meaning to Foobot readings lead us to fundamental questions we eluded from the beginning: what do we want to detect? Air quality events. Ok, but what is it?&lt;/p&gt;

&lt;p&gt;Air quality event definition isn’t as simple as it sounds. One may think of all pollution events that can happen at home, like when you burn your cooking, that will generally translates into a sudden increase of particulate matters (PMs).&lt;/p&gt;

&lt;p&gt;But events aren’t only about pollution, and we wanted to be able to detect more to get. What about opening a window? At first sight, it should be revealed by a change in temperature and/or humidity. But in what direction (increase or decrease)? In what proportion? 
This kind of event is also depending on external factors like season and location: in winter in New York, opening the window will have a different event signature than during summer, or in a different location like countryside.&lt;/p&gt;

&lt;p&gt;Also, events can be defined by different features, and not only by a sensor value at a specific moment of time: volatility of the value, difference between the minimum and maximum value over a period of time, necessary time to revert to initial value…&lt;/p&gt;

&lt;p&gt;More over, let’s think about sensor value context: a small change in one sensor value on a short period of time may not be significant when seen alone. But coupled with another small change from another sensor, this could get interesting. Even more if all sensors are impacted. And direction also has its role to play (increase vs decrease): a combination of increases and/or decreases may be frequent and not seen as an event, but another combination could be more rare, and worth paying attention to it.&lt;/p&gt;

&lt;p&gt;Let’s have a look at below graph: it’s 24 hours in the day of a Foobot. Lot of things happen and it illustrates well the complexity of detecting events, without generating too much noise for the user (not every variation is an event). Some events are brutal changes of values in a short period of time, some last longer and there is a bigger period of time between start and end phases. Some involves all sensors but the 3 last are only reflecting on temperature and humidity.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/airqual_events_class/sensors_values_events.png&quot; alt=&quot;sensors graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, air quality event detection is a non trivial problem. It requires more than simple algorithm or heuristics: this is a very good application of using machine learning algorithms.&lt;/p&gt;

&lt;h2 id=&quot;air-quality-events-detection&quot;&gt;Air Quality Events Detection&lt;/h2&gt;

&lt;h3 id=&quot;oddities-are-in-the-air&quot;&gt;Oddities are in the air&lt;/h3&gt;

&lt;p&gt;Air quality events we want to detect are actually abnormal and most probably infrequent changes in the values sent by Foobot sensors. For instance, when you open the oven, important amount of PMs can be released (if something burnt), or when you open your window, temperature and humidity may change, as well as VOCs, CO2 and PMs.&lt;/p&gt;

&lt;p&gt;We took the following approach: we know we don’t know all combinations of the events we want to detect, and we don’t even know the events we want to detect. Actually, we want to detect and classify much more than a few categories, and the best way is to let users tell us what they do.&lt;/p&gt;

&lt;p&gt;We also want to let users know with no delay that something happen and ask them to tag the event, providing a list of possible categories, but also a free text field so they can create new categories. 2 benefits to this approach:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;users want to be able to react immediately when air quality degrades&lt;/li&gt;
  &lt;li&gt;reducing time between detection and notification gives users more chances to remember what they were doing at that time. Sending notifications or emails every day in batch wouldn’t be efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To achieve this, we needed to design and implement 2 technical parts:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;something able to detect anomalies by comparing a vector of values to an existing and already organized set of vectors&lt;/li&gt;
  &lt;li&gt;a streaming layer to continuously analyze incoming data&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;machine-learning-to-the-rescue&quot;&gt;Machine learning to the rescue&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Anomaly_detection&quot;&gt;&lt;em&gt;Anomaly detection&lt;/em&gt;&lt;/a&gt; (or &lt;a href=&quot;https://en.wikipedia.org/wiki/Outlier#Detection&quot;&gt;&lt;em&gt;outlier detection&lt;/em&gt;&lt;/a&gt;) is a common problem in data-mining.
The concept of anomaly detection is quite general, but the idea is to detect outliers (observations very distant to others) from a dataset, and that can be used in a variety of areas like hardware failure detection, intrusion detection systems, or fraud detection.&lt;/p&gt;

&lt;p&gt;There are also different ways to tackle the problem, with a complexity ranging from basic to very complex (neural networks).&lt;/p&gt;

&lt;p&gt;We decided to head into &lt;a href=&quot;https://en.wikipedia.org/wiki/K-means_clustering&quot;&gt;K-Means&lt;/a&gt; which is a clustering technique (unsupervised learning): given a number &lt;em&gt;k&lt;/em&gt;, the algorithm will divide the dataset into &lt;em&gt;k&lt;/em&gt; groups (or &lt;em&gt;clusters&lt;/em&gt;) in a way that minimizes distance between cluster center and data points. K-Means is also relatively fast to train, and its output is easy to understand (compared to other algorithms).&lt;/p&gt;

&lt;p&gt;When applied to the entire dataset, K-Means training will output a model composed of &lt;em&gt;centroids&lt;/em&gt;: basically coordinates of cluster centers. Centroids are computed to minimize distance between themselves and surrounding data points.&lt;/p&gt;

&lt;p&gt;Parameter &lt;em&gt;k&lt;/em&gt; is left to the discretion of the data scientist: depending on clustering task needs, you may want more or less cluster centers. If minimizing distance is your objective, it’s possible to iteratively train models while incrementing &lt;em&gt;k&lt;/em&gt;, and compute average distance of each data point to its centroid for each run: after a specific value of &lt;em&gt;k&lt;/em&gt;, accuracy will stop increasing (plateau).  On the contrary, if you want to rough outline patterns in your data, you may want to keep &lt;em&gt;k&lt;/em&gt; low.&lt;/p&gt;

&lt;h3 id=&quot;anomaly-detection-with-k-means&quot;&gt;Anomaly detection with K-Means&lt;/h3&gt;

&lt;p&gt;Let’s dig into anomaly detection, as we talked about K-Means basics, but it’s not yet clear at this point how it can help to detect anomalies.&lt;/p&gt;

&lt;p&gt;It’s quite simple: every time a data point will be classified with our trained model, the output will be the coordinates of the closest centroid. We can then compute &lt;a href=&quot;https://en.wikipedia.org/wiki/Euclidean_distance&quot;&gt;euclidean distance&lt;/a&gt; between data point vector and centroid vector to see how far it is from the cluster center. Anomaly detection will make us of this distance: if data point is far, it basically means it’s something we didn’t see very often in the training dataset.&lt;/p&gt;

&lt;p&gt;Going a step further, from the model we trained we’ll only select centroids for clusters that classified the more entries. If we take a basic example of 5 clusters, initial training could output something like below:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1: (0.1, 0.2, 0.1, 0.5)    =&amp;gt; 100000 entries
2: (-0.2, 0.1, -0.05, 0.1) =&amp;gt; 50000
3: ...
5: (4, -2, 4, 4)           =&amp;gt; 100
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The more entries are classified in a cluster, the more frequent they appear in the dataset. Differently said, clusters with more entries represent the more frequent patterns in the data set.&lt;/p&gt;

&lt;p&gt;With a 3D representation, it gets clearer how outliers or anomalies will stand out of the crowd: a pack of points reprensenting clusters with most values (below clusters are grouped but you could get groups with a distance between each of them), and suddenly an anomaly, classified in one of the existing clusters but far from the center.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/airqual_events_class/clustering_outlier.png&quot; alt=&quot;clustering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To wrap this up, we’re using anamoly detection technique based on K-Means, but we cut the model from its less populated clusters. We’ll then use distance computation between vector to classify and its centroid to decide if it’s an event or not.&lt;/p&gt;

&lt;h3 id=&quot;events-and-datapoints&quot;&gt;Events and Datapoints&lt;/h3&gt;

&lt;p&gt;Ok but then, how do we feed the trainer? This is part of the &lt;em&gt;feature selection&lt;/em&gt; process, that makes us pick some values or derivatives of values (like aggregations) but not others from the data set, in order to train the model.&lt;/p&gt;

&lt;p&gt;Being specific here, we’re interested in variations of sensor values over a period of time. Intuitively, sensor values variation between now and a few minutes ago is what can tell better that something is happening as it reflects a change in the air composition. Absolute values alone are not interesting, because, for instance, you could have indoor air with constant high VOC values.&lt;/p&gt;

&lt;p&gt;Finally, while training models with this kind of data we rapidly realized that clusters with less data had coordinates representing the most important variations in sensors values, while the ones with more data were associated with small variations. Selecting only the latter gave us a clustering model that could outline anomalies.&lt;/p&gt;

&lt;h2 id=&quot;detecting-in-near-real-time&quot;&gt;Detecting in near real-time&lt;/h2&gt;

&lt;p&gt;Near real-time detection is where we wanted to go from the beginning. Detecting events with a few hours delay with a batch would have reduced the benefit of it all, as the user couldn’t be notified immediately.&lt;/p&gt;

&lt;p&gt;Here, near real-time detection means continuous stream of datapoints that a job transforms and submits to the classifier. In Spark Streaming, it translates into a sliding window that maintains a state for each device. This state is a representation of the variations of sensor values for the device over a period of time. Spark Streaming offers several operators that comes in handy. See &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations&quot;&gt;Spark Streaming - Window Operations&lt;/a&gt; for details.
Spark Streaming also allows us to load a K-Means model and to submit vectors to be classified in a continuous manner.&lt;/p&gt;

&lt;p&gt;Upon reception, datapoints are transformed and some flags are checked to help make better decisions, like wether or not taking datapoint into account, applying custom transformations, etc. Then we submit the state to the K-Means classifier and depending on distance to the closest cluster, we tag it as an indoor air quality event or not.&lt;/p&gt;

&lt;p&gt;Event end is also a matter of clustering: we consider an event as finished if variations between last datapoint received and first event datapoint are classified close to a highly populated cluster centroid.&lt;/p&gt;

&lt;p&gt;Sensitivity of event detection and event closing are depending on the configurable threshold that we compare to each distance &lt;code class=&quot;highlighter-rouge&quot;&gt;euclid_dist(state_vector - centroid)&lt;/code&gt;. In the case of detection, the bigger the threshold is, the less sensitive detection will be. And it’s the exact opposite for event closing. It took us quite some time to find &lt;em&gt;interesting&lt;/em&gt; thresholds: it was all about working with beta testers, checking large amount of detected events, and fine tuning.&lt;/p&gt;

&lt;p&gt;When event ends, not only we can easily retrieve datapoints that caused the event to be triggered, but we can also analyse event life: max and min values, variance, duration… All this data will be extremely useful to understand patterns of indoor air quality events.&lt;/p&gt;

&lt;p&gt;Below diagram illustrates this flow&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/airqual_events_class/real_time_detect_diag.png&quot; alt=&quot;real time detection&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;fooboters-own-the-value&quot;&gt;Fooboters own the value&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000/assets/airqual_events_class/foobot_app_notif.png&quot; alt=&quot;ingestion&quot; class=&quot;callout&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Detecting events in a streaming manner has some benefits: our users can be informed immediately, and they can tell us what it is. When an event is detected, it’s transformed into a push notification, that users can open in Foobot mobile app, then select in a category he or she thinks was the root cause of the event. This information is then preciously saved, along with event characteristics.&lt;/p&gt;

&lt;p&gt;Fooboters have been more than kind with us: not only we got a massive amount of tags, but they also helped us expending our list of categories. As event types list is not closed - users have the ability to give their own tag if they don’t find one in the list of choices - we are able to add new event classes, or create sub categories to refine events classification.&lt;/p&gt;

&lt;p&gt;With the help of our users, we collected an important dataset of tags that we’re able to join with event characteristics, in order to form another training dataset: the one that will help building an air quality events classification model!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we’ve investigated in details some of the internals of indoor air quality event detection at Airboxlab. There is a lot more to say about the different approaches we’ve tried, the failures we faced, what we’ve learned.&lt;/p&gt;

&lt;p&gt;Detection is non trivial, but we’re fairly satisfied with what we obtained. We regularly monitor accuracy of detected events, and it’s quite interesting to see amount of events and conditions of classifications. We’ve also set configurable thresholds that allow to increase or decrease sensitivity of detection. Still, there is room for improvement; for instance, we didn’t dig too much into detecting several events happening in the same window of time. This would involve managing competing events and states. Probably interesting to look into, but somewhat difficult to compare to single-state-per-device (current) technique in terms of relevance, accuracy, and user friendlyness.&lt;/p&gt;

&lt;p&gt;In our next article we’ll discuss the next step in building an air quality event processing pipeline: classification. Of course, collecting all this data reveals its full potential only if we try to find patterns in it, and make our users benefit from our findings. Knowing precisely what’s happening in the air of your home can give you precious information for improving it!&lt;/p&gt;

</description>
        <pubDate>Mon, 23 Jan 2017 16:00:00 +0100</pubDate>
        <link>http://0.0.0.0:4000/machine/learning/2017/01/23/airqual_events_class_part1.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/machine/learning/2017/01/23/airqual_events_class_part1.html</guid>
        
        
        <category>machine</category>
        
        <category>learning</category>
        
      </item>
    
      <item>
        <title>A streaming pipeline for the IoT with Apache Spark &amp; microservices</title>
        <description>&lt;style type=&quot;text/css&quot;&gt;
.callout {
    float: right;
    margin-left: 5px;
}
&lt;/style&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/data_pipeline/oilpipeline.jpg&quot; alt=&quot;oil pipeline&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;what-is-airboxlab-doing-with-foobot-data&quot;&gt;What is Airboxlab doing with Foobot data?&lt;/h2&gt;

&lt;p&gt;We build Foobot, which sends indoor air quality data on a regular schedule. This data represents our users most valuable information, and is why they are buying a Foobot for. 
This data itself is the core of our business, and as engineers we have to secure the process of receiving and storing it.&lt;/p&gt;

&lt;p&gt;However, data alone isn’t enough to give users a smart and complete experience so they can learn and act to improve their environment: an important part of the value is in the processing of this data, how we react to it, and at what speed. 
Indoor air quality is a matter of comfort and health, hence being alerted too late that the air you breath is polluted reduces interest and impact of the product a lot. In a similar manner, if you used a toxic cleanser but your ventilation system kicks in too late you just bought a mute doctor: he knows what you’re suffering from but can’t help!&lt;/p&gt;

&lt;p&gt;That’s why engineers at Airboxlab invest a lot in building a reliable, scalable and extensible streaming data pipeline. We want to make sure data is safe, that we react appriopriately and in a timely fashion to it, and that the next useful external system integration (be it a thermostat, HVAC system, IFTTT-like platform, customized stream…) will be straightforward.&lt;/p&gt;

&lt;h2 id=&quot;anatomy-of-our-streaming-pipeline&quot;&gt;Anatomy of our streaming pipeline&lt;/h2&gt;

&lt;h3 id=&quot;sources-sinks--jobs&quot;&gt;Sources, Sinks &amp;amp; Jobs&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Sources&lt;/strong&gt; in our pipelines are various. Most data (in volume) is emitted by Foobot sensors, but there are also events sent by applications (mobile, web), internal sources of static data (for instance device or user definitions that can serve to enrich context), and intermediate results in the pipeline that can be served as sources in other steps.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sinks&lt;/strong&gt; are also of various nature. We can categorize them as following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;persistent storage, like SQL and NoSQL databases, HDFS and S3&lt;/li&gt;
  &lt;li&gt;transient like message brokers to which analysis from processed input are sent on structured topics. Downstream pipeline clients subscribe to the topics they are interested in, process incoming messages, and send results to another sink&lt;/li&gt;
  &lt;li&gt;external like external API offered by partners&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Jobs&lt;/strong&gt; are the processes that transform input from a source to a desired result and output it to a sink. We have 2 types: &lt;em&gt;Spark Streaming&lt;/em&gt; jobs and &lt;em&gt;microservices&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Communication&lt;/strong&gt; between sources, sinks &amp;amp; jobs depends on physical location of them (e.g. Foobot devices are living in users networks, data is sent through WAN), performance requirements (in memory vs over network), and flexibility (need to start/stop a source/sink dynamically).&lt;/p&gt;

&lt;p&gt;Finally, a streaming pipeline is all about sources, sinks and how data goes from one to another. With (you guess so) complex interactions between them. That’s what I’m going to detail in the next section.&lt;/p&gt;

&lt;h3 id=&quot;sensor-data-streaming-pipeline&quot;&gt;Sensor data streaming pipeline&lt;/h3&gt;

&lt;p&gt;This is our main data pipeline, the richer and more complex one (there are also other peripheral pipelines that fulfill specific requirements). We can summarize its functions as following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ingestion&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/data_pipeline/data_pipeline_ingestion.png&quot; alt=&quot;ingestion&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Between sensor data emission and storage the path must be as short as possible. The shorter it is, the less we expose ourselves to failure and eventually data loss. Hence storage happens right away after reception. Job responsible for receiving and storing is extremely simple, load-balanced, and tolerant to failure.&lt;/p&gt;

        &lt;p&gt;Also, we don’t throw anything, even “junk” data that can sometimes be sent during temporary or permanent failure of a sensor: this won’t be taken into account by downstream consumers of the main pipeline but is used for failure detection.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Transformation&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Sensor data is sent in a specific, raw, compressed format in order to save bandwidth. This step transforms this data into a json document. It also performs input validation in the meantime.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Contextual enrichment&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;Raw sensor data is stored but not used as is downstream: we need to calibrate them in order to have meaningful values. Each device has its own calibration (each sensor is slightly different). Device-specific static data is also added to the context, and the whole forms the first rich json document that is sent to multiple downstream consumers.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Aggregations &amp;amp; statistics computing&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Stats&lt;/strong&gt; are continuously computed for each device connected to our backend. Most of them are quite basic, like cumulative moving averages for each sensor, some others are based on regressions, like averages of top minimum or maximum values.&lt;/p&gt;

    &lt;p&gt;Most statistics computations never imply loading historical values: this would be a scaling problem. Whenever possible, we use a rolling/cumulative version of the statistic.&lt;/p&gt;

    &lt;p&gt;Statistics are used by several consumers:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;calibration adapter that is used to adapt sensors baseline&lt;/li&gt;
      &lt;li&gt;other jobs in the pipeline that can trigger events based on statictics values&lt;/li&gt;
      &lt;li&gt;reporting tools, for instance one that email a periodic email to users telling him how was air quality in the past days or weeks&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;We also perform &lt;strong&gt;aggregations&lt;/strong&gt; that are used downstream or served to users (values available by API, used by mobile and web apps). It reduces average response size and latency.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Alerting&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/data_pipeline/data_pipeline_alerting.png&quot; alt=&quot;ingestion&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Alerting is the process of raising an alert when a particular event occurs. That is often related to a sensor data value crossing a standard or user-defined threshold, what we call instant threshold crossing, but can be more complex when it comes to “air quality event” detection. A simple type of event would be a pollution event, one that starts when a pollutant crosses a threshold and ends when it comes back to normal. This implies using mechanisms like windowing and stateful operations to preserve event state, or applying hysteresis for values constantly crossing thresholds up and down.&lt;/p&gt;

    &lt;p&gt;There are 2 main types of consumers to these alerts:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Direct user notifiers, mostly using mobile push notifications&lt;/li&gt;
      &lt;li&gt;External systems notifications: for instance we can trigger the ventilation system linked to an Ecobee thermostat if particulate matter level is higher than user-defined threshold.&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Machine learning&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;We apply machine learning at various levels, from calibration baseline improvement to air quality events detection. We use algorithm implementations provided by Spark ML that can be integrated in Spark Streaming jobs: here Spark reveals all its power, as all these bricks feet well together.
Downstream consumers are somehow the same as for alerting.&lt;/p&gt;

    &lt;p&gt;There are things to say here, but we’ll cover this in a future blog post.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Backup&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/data_pipeline/data_pipeline_backup.png&quot; alt=&quot;ingestion&quot; class=&quot;callout&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;Even backup can be done in a near real-time manner: instead of fetching and storing data in an external backup store on a daily basis, why not benefit from streaming pipeline to do it at event processing time. This is how we implemented our incremental and asynchronous backup system. This has several advantages:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;2 seat belts: data is stored on arrival, and almost immediately backed up.&lt;/li&gt;
      &lt;li&gt;we can develop alternative pipelines to handle temporary or non mission critical tools: we store backup data in HDFS, that can be a source for &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html#basic-sources&quot;&gt;Spark Streaming&lt;/a&gt;.&lt;/li&gt;
      &lt;li&gt;we have an up-to-date offline version of our data on which we can perform heavy data mining and model training.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;keeping-the-pipeline-flexible&quot;&gt;Keeping the pipeline flexible&lt;/h2&gt;

&lt;p&gt;The backbone of our pipeline relies on Spark Streaming, which allows us to dedicate more or less resources (CPU &amp;amp; RAM) to streaming jobs, making it able to scale well. Dividing each functional process into separate jobs allows us to re-deploy or scale them independently.&lt;/p&gt;

&lt;p&gt;An other important thing in our day-to-day job is to be able to “plug” a new job at the “periphery” of the pipeline quickly. For instance, we often decide to interact with a new external vendor API, and we don’t want to think about anything else than:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what will the service subscribe to?&lt;/li&gt;
  &lt;li&gt;how will it interact with the API?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most importantly, we want to avoid modifying other jobs in the pipeline as much as possible. This allows us to develop and deploy the new service without restarting anything else.&lt;/p&gt;

&lt;p&gt;On another hand, we want subscriptions to be dynamic too. For instance, a new user connects on IFTTT and wants its &lt;a href=&quot;https://ifttt.com/connect/foobot/wemo_switch&quot;&gt;Foobot to turn on his WeMo switch&lt;/a&gt;  whenever global pollution level is too bad. To do that, we will record user configuration but also make the service responsible for interacting with IFTTT listen to relevant user’s device events. 
Similarly, if user disconnects from Foobot channel, we don’t want the service keep listening to his thresholds alerts.&lt;/p&gt;

&lt;p&gt;In order to fulfill these requirements, we opted for a &lt;strong&gt;microservices&lt;/strong&gt; architecture very early. This brings the following benefits:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;easier to develop a new service&lt;/em&gt;: we invested a bit in simplifying services creation, so creating a new one is a matter of minutes.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to extends a service functionality&lt;/em&gt;: let’s say you want to add a trigger to your IFTTT channel: you’ll only need to change this service code, and retest it. Nothing else. This greatly reduces the risk of regression in other functionalities, and allows us to deploy faster and more often&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;efficient communication&lt;/em&gt;: each service subscribes and reacts to the events it’s supposed to listen to. We structured messaging topics so that services receive only what they need.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to test&lt;/em&gt;: well, easier than having to deploy the whole pipeline and re-testing everything. Testing a pipeline is still harder than a classic piece of software though, so we invested in a internal testing microframework that helps writing integration tests.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;easier to scale&lt;/em&gt; a particular integration: one of our integration becomes popular? we can spin up new services only for this type, making the whole architecture cost-efficient.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/data_pipeline/data_pipeline_subscribers.png&quot; alt=&quot;subscribers&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This article gave an overview of one of the most critical part of our system, and explains why we choose Spark Streaming and microservices to implement it. 
A future series of articles will dive into more specific parts of the pipeline.&lt;/p&gt;

</description>
        <pubDate>Mon, 29 Aug 2016 14:00:00 +0200</pubDate>
        <link>http://0.0.0.0:4000/streaming/microservices/iot/spark/real-time/2016/08/29/streaming-microservices.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/streaming/microservices/iot/spark/real-time/2016/08/29/streaming-microservices.html</guid>
        
        
        <category>streaming</category>
        
        <category>microservices</category>
        
        <category>iot</category>
        
        <category>spark</category>
        
        <category>real-time</category>
        
      </item>
    
      <item>
        <title>Lean Approach to Spark Streaming with AWS EC2</title>
        <description>&lt;p&gt;We’ve been using &lt;a href=&quot;http://spark.apache.org&quot;&gt;Apache Spark&lt;/a&gt; for 1 year, and we wanted to share some thoughts and tips about it.&lt;/p&gt;

&lt;p&gt;Spark is beautiful. It has a strong and simple API, a vibrant community, a wide ecosystem and lot of satellite projects. However, it doesn’t come for free: you need to understand its API, internal structures, and deployment methodologies. Setting up a cluster, maintaining, designing applications and jobs, … All of this can be overwhelming and looks like a daunting task at first.&lt;/p&gt;

&lt;p&gt;The goal of this article is to provide overview, instructions and tips on how to build, deploy and maintain a distributed data analytics application based on Spark, with a particular focus on Spark Streaming.&lt;/p&gt;

&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;

&lt;p&gt;We decided to go for Spark at &lt;a href=&quot;https://foobot.io&quot;&gt;Airboxlab&lt;/a&gt; firstly to ingest and analyze streams of sensors data. We design, build and sell air quality monitoring products, that are used to monitor and trigger actions based on air quality measurements.&lt;/p&gt;

&lt;p&gt;We had several options on the table (AWS Kinesis, Apache Storm, …) but we decided to pick Spark for the following reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;unified platform for data streaming and batch analysis (lambda architecture), with machine learning capabilities&lt;/li&gt;
  &lt;li&gt;heterogeneous team with different background and technical skills&lt;/li&gt;
  &lt;li&gt;tight budget&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As of now, some other options may be available to you, like AWS Kinesis Firehose.&lt;/p&gt;

&lt;p&gt;We started with Spark 1.2.0 in test, and went in production with 1.3.0 few months later.&lt;/p&gt;

&lt;p&gt;Our first Spark job was a streaming job, one to clean and store sensor data sent by devices. It made us discover Spark architecture, application deployment process, and fault tolerance semantics.&lt;/p&gt;

&lt;h2 id=&quot;spark-cluster-topology&quot;&gt;Spark cluster topology&lt;/h2&gt;

&lt;p&gt;I won’t go into details here as it has been extensively described in main &lt;a href=&quot;?&quot;&gt;Spark documentation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here is just a quick reminder of main Spark processes&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Master&lt;/em&gt;: this is the main process responsible for coordinating cluster, scheduling jobs, restarting failed workers, …&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Worker&lt;/em&gt;: a worker node is where executors can be launched.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Executor&lt;/em&gt;: started by workers for a given application. There may be 1 or thousands of them, depending on task configuration. They execute the application and store data in memory or in persistent stores.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Driver&lt;/em&gt;: application submitted to the cluster that contains the main() method.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://spark.apache.org/docs/latest/img/cluster-overview.png&quot; alt=&quot;Cluster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are 3 deployment methods if you want to run your own cluster:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Standalone (comes with AWS EC2 deployment scripts)&lt;/li&gt;
  &lt;li&gt;Mesos&lt;/li&gt;
  &lt;li&gt;YARN&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And there are several companies that sell Spark cluster management, like Databricks (created by creators of Apache Spark), Hortonworks, Cloudera, and even AWS and Google are proposing services.&lt;/p&gt;

&lt;p&gt;Here comes the first question you may be asking yourself: will I invest in my own Spark clusters (probably several if you have test environments), or can I use an hosted and managed cluster?&lt;/p&gt;

&lt;h3 id=&quot;own-cluster-vs-managed-cluster&quot;&gt;Own cluster VS Managed cluster&lt;/h3&gt;

&lt;p&gt;Having your own cluster will let choose your configuration, that may not be easy with a provider. For instance, Databricks doesn’t let you choose your AWS instance type (it’s a r3.2xlarge and that’s it!).&lt;/p&gt;

&lt;p&gt;Another important point is that, especially in the case of clusters dedicated to batches, or even with streaming applications that run on over-sized clusters where there is CPU and RAM available, you could share instances for other tasks. Mesos and YARN let you share resources between clusters, so you can efficiently allocate resources and avoid wasting money.&lt;/p&gt;

&lt;p&gt;But there are also advantages using an hosted solution: you don’t need to know a lot about Spark or system administration before you start your first data exploration job. Not all teams have someone available to setup (and maintain) a cluster, and Spark is all about giving instant access to big data analysis. In that perspective, a managed cluster is a good solution.&lt;/p&gt;

&lt;p&gt;It can also be interesting if you want to temporarily create a cluster: Spark version upgrade testing, scheduled jobs, external users access to your data and jobs, …&lt;/p&gt;

&lt;p&gt;Last but not least: you don’t need a cluster to start testing Spark! You will see it when you start reading &lt;a href=&quot;http://spark.apache.org/docs/latest/programming-guide.html&quot;&gt;Spark programming guide&lt;/a&gt;, Spark can run on your own machine, just pick a reduced dataset and don’t try to load terabytes of data.
That’s one of the main strengths of Spark, you can develop and test your whole job locally.&lt;/p&gt;

&lt;h3 id=&quot;deploying-spark-on-aws-ec2&quot;&gt;Deploying Spark on AWS EC2&lt;/h3&gt;

&lt;p&gt;Say you decide to give a try to Spark with your own standalone cluster, on AWS. Spark comes with a set of scripts that let you deploy a cluster from a command line. Documentation is available &lt;a href=&quot;http://spark.apache.org/docs/latest/ec2-scripts.html&quot;&gt;here&lt;/a&gt;. You can deploy inside or outside of a VPC, define your spot instance price, or choose your instance types for both master and workers.&lt;/p&gt;

&lt;p&gt;Speaking of master and workers, there is a first budget optimization you can do here: you can share the master node, that will rather go unoccupied with only the master process and your driver. You can start one or more workers on it.&lt;/p&gt;

&lt;p&gt;Spark EC2 will also do several other things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;create 2 &lt;strong&gt;Hadoop&lt;/strong&gt; clusters, one said ephemeral because it’s started on SSD instance storage, another said persistent (not started by default). It allows you to store and fetch data on HDFS, and it’s also used by Spark internals and application checkpointing.&lt;/li&gt;
  &lt;li&gt;create a &lt;strong&gt;Tachyon&lt;/strong&gt; cluster for in memory caching&lt;/li&gt;
  &lt;li&gt;add monitoring agents with &lt;strong&gt;Ganglia&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When your cluster is built, there are 2 web UIs available where you can monitor Spark and your instances:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;http://&amp;lt;spark_master&amp;gt;:8080/&lt;/code&gt; is the Spark Web interface. There you can check health of master, workers, executors and jobs.&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;http://&amp;lt;spark_master&amp;gt;:5080/ganglia/&lt;/code&gt; is the Ganglia master UI (monitoring of hardware, processes, memory, …).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;cluster-management&quot;&gt;Cluster management&lt;/h3&gt;

&lt;p&gt;Your cluster is up and running, you may now wonder what you will have to do to keep it healthy. There are some things you need to automate to ensure nothing breaks without you being alerted, and also to simplify provisioning (adding and retiring nodes).&lt;/p&gt;

&lt;h4 id=&quot;adding-nodes&quot;&gt;Adding nodes&lt;/h4&gt;

&lt;p&gt;Spark EC2 scripts doesn’t help on this (hey, they already did a lot!). The way we do it at Airboxlab is based on AWS AMIs: we build an AMI from one of the worker nodes freshly created and configured.&lt;/p&gt;

&lt;p&gt;The first thing is to let your master node know about this new node: you have to edit spark configuration (&lt;em&gt;slaves&lt;/em&gt; files under spark and spark-ec2) and hadoop configuration (&lt;em&gt;slaves&lt;/em&gt; under ephemeral-hdfs) to add the host name of your newly created instance. Don’t forget to &lt;em&gt;r-sync&lt;/em&gt; all these files (&lt;em&gt;spark-ec2/copy-dir&lt;/em&gt; command).&lt;/p&gt;

&lt;p&gt;When you launch a new instance from this AMI, there are processed that must started so your node is operational:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;start Hadoop data node: &lt;code&gt;sudo /root/ephemeral-hdfs/bin/start-dfs.sh&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;start Ganglia agent: &lt;code&gt;sudo /usr/sbin/gmond&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;start Spark worker: &lt;code&gt;nohup sudo /root/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://&lt;MASTER_HOSTNAME&gt;:7077 &amp;amp;&amp;lt;/code&amp;gt;&lt;/MASTER_HOSTNAME&gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note: if you use Tachyon, above steps apply too.&lt;/p&gt;

&lt;h4 id=&quot;scheduling-clean-up&quot;&gt;Scheduling clean up&lt;/h4&gt;

&lt;p&gt;Jobs are started on worker nodes and will produce logs in &lt;code&gt;$SPARK_HOME/work/&lt;/code&gt;. Each application jar version will also be stored on each worker running it. If you run a lot of them, disk space will decrease.
Below are cleanup tasks that can be scheduled with &lt;code&gt;cron&lt;/code&gt; on each worker node and that removes logs and jars after 30 days. &lt;strong&gt;Warning&lt;/strong&gt;: this assumes you redeploy at least every 30 days!&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;find /root/spark/work/ -type f -name &lt;span class=&quot;s2&quot;&gt;&quot;std*&quot;&lt;/span&gt; -mtime +30 -delete
find /root/spark/work/ -type f -name &lt;span class=&quot;s2&quot;&gt;&quot;*.jar&quot;&lt;/span&gt; -mtime +30 -delete
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Also, Spark AWS deployment comes with a Hadoop cluster that also needs maintenance. Hadoop logs cleanup task can be scheduled the same way:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;find /mnt/ephemeral-hdfs/logs -name &lt;span class=&quot;s2&quot;&gt;&quot;hadoop*.log.201*&quot;&lt;/span&gt; -type f -mtime +10 -delete
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;system-failures-handling&quot;&gt;System failures handling&lt;/h4&gt;

&lt;p&gt;You may have started with 1 or 2 worker nodes, but you may end up with dozens of them. Eventually, one or more servers will fail. They will. You have to anticipate it: a streaming job may not stop too long!
Few tips to anticipate a failure, in case you chose standalone deployment mode (different approaches apply for Mesos or YARN):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On AWS, &lt;strong&gt;create AMIs&lt;/strong&gt; from both master and worker node types. We already talked about the latter, but it can help to have an image for the former. This way you can start a new master instance and restart your workers one by one to point to the master&lt;/li&gt;
  &lt;li&gt;Spark deployment guide already covers this: have a &lt;strong&gt;standby master&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;You could also study the creation of a &lt;strong&gt;standby cluster&lt;/strong&gt;: one that is an exact replica of the running one, but that you let shut down (so you save the price of running instances, but not EBS volumes unfortunately). It can be created on a different AWS availability zone or region than the other one, in case the first may become unavailable for a moment. It can also be used for &lt;em&gt;blue/green&lt;/em&gt; types of deployment.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h4&gt;

&lt;p&gt;Monitoring is essential and can’t be skipped. In our case, with streaming jobs that must run 24/7 in multiple data-centers, monitoring and alerting are vital.&lt;/p&gt;

&lt;p&gt;Your first weapons are Spark and Ganglia UIs, which are very good at collecting monitoring information about instances. Spark UI will help you find failed jobs and stages, application exceptions (log files are accessible in &lt;em&gt;Executors&lt;/em&gt; tab), receiver exceptions (&lt;em&gt;Streaming&lt;/em&gt; tab).&lt;/p&gt;

&lt;p&gt;You also need to be alerted when something goes wrong; that’s something we do with logstash (1 by cluster node) by analyzing jobs and workers log files for specific exceptions.&lt;/p&gt;

&lt;p&gt;Spark master also comes with a &lt;a href=&quot;http://spark.apache.org/docs/latest/monitoring.html#rest-api&quot;&gt;REST API&lt;/a&gt; that you can query periodically to check health of each job.&lt;/p&gt;

&lt;p&gt;In the particular case of a streaming application, you can also monitor:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;batch processing time&lt;/strong&gt;: if it’s frequently above your configured batch interval, your job is too slow at processing received and records and lags behind. Another hint for that is an increasing number of waiting batches. You need to either increase batch interval, add cores/mem to your job, optimize it.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;input stream pending records&lt;/strong&gt;: if you use a broker like Kafka or RabbitMQ, check that your job is able to process incoming events. Spark has flow control mechanisms to move pressure back to the sender, still you may want your data to be processed in a timely manner.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spark-application-development&quot;&gt;Spark application development&lt;/h2&gt;

&lt;p&gt;Good, you have your own cluster now! It’s time to run something on it. This part won’t cover the basics of how to write a streaming job with Spark Streaming API, but rather try to list some useful tips on application development and life-cycle management.&lt;/p&gt;

&lt;p&gt;A very complete programming guide is available &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html&quot;&gt;here&lt;/a&gt; and is a good start point. Working examples are available in &lt;a href=&quot;https://github.com/apache/spark/tree/master/examples/src/main/scala/org/apache/spark/examples/streaming&quot;&gt;Spark github repo&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;cores-are-expensive&quot;&gt;Cores are expensive&lt;/h3&gt;

&lt;p&gt;You’re still in the early stages but want to use Spark anyway. Spark streaming applications require at least 2 cores to run, and that can look overwhelming if you already think about the dozen of small streaming jobs you want to write.
A quick solution is to write a &lt;strong&gt;single driver with several output operations&lt;/strong&gt;. You can then make different jobs share the same resources, within the same driver execution process. It’s still possible to scale, as it will benefit from adding additional cores to driver the same way a driver with a single output operation would do (you’ll have to define &lt;code&gt;spark.streaming.concurrentJobs&lt;/code&gt; to parallelize processing of jobs in a single driver) . Another advantage is you can create much cheaper integration test environments.&lt;/p&gt;

&lt;p&gt;The drawbacks are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;you loose code and process isolation, and you’ll have to redeploy everything even when you want to upgrade a single job. Code your driver with future splits in mind.&lt;/li&gt;
  &lt;li&gt;debugging can be much harder.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;stateful-operators-think-twice&quot;&gt;Stateful operators: think twice&lt;/h3&gt;

&lt;p&gt;They look apealing, and can do really great job. However, logic for stateful operations in a stream are more complex than other kinds, and more complex to debug.
First of all, a common mistake we made at the beginning (saw it also in different mailing lists conversations), is to use stateful operations as persistent stores. They are not, of course, and they are wiped out when checkpoint directory is cleared. You have to save everything that needs to be in a reliable persistent storage. Stateful operations are great to store transitive states that you can afford to lose or are easy to store and restore on startup.
Complexity in writing a working and maintainable job is also something to avoid. There are usually other ways to write the same job without using stateful operators (like persisting and fetching everything in DB)&lt;/p&gt;

&lt;h3 id=&quot;event-driven&quot;&gt;Event-driven&lt;/h3&gt;

&lt;p&gt;Think event-driven: streaming applications will run micro batches every few seconds. Is it ok to fetch static or live data from your relational database everytime, for every received record? It is a possible solution, but it won’t scale well. Prefer an event-driven approach: when you change the value of a column or row in DB that the streaming app should be aware of, also send a message asynchronously to a specific topic that will be broadcasted by your message broker.&lt;/p&gt;

&lt;p&gt;You can then merge different &lt;code&gt;DStream&lt;/code&gt; in a single job using &lt;code&gt;DStream.join&lt;/code&gt;: if the first is of &lt;code&gt;(K,V)&lt;/code&gt; and the second &lt;code&gt;(K,W)&lt;/code&gt;, the merged stream will be of &lt;code&gt;(K,(V,W))&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;use-pooling-everywhere&quot;&gt;Use pooling everywhere&lt;/h3&gt;

&lt;p&gt;It’s strongly recommended to use connection pooling everywhere. It is true with database connections, and you’re probably already using it in your applications. But it’s also true with connections to other systems, like your message broker. For that purpose, a simple solution is to use &lt;em&gt;Apache Commons Pool&lt;/em&gt; library.&lt;/p&gt;

&lt;h3 id=&quot;batch-interval-and-recovery&quot;&gt;Batch interval and recovery&lt;/h3&gt;

&lt;p&gt;When you design your job and calculate a relevant batch interval, you will take into account estimated messages rate, probable spikes in load, capacity of dedicated hardware, … A thing that must also be part of the reasoning is recovery in case of failure: if a driver (or any other piece of the system) fails and messages aren’t consumed for a while, they will pile up on the producer side. When application restarts, it will have to handle a massive and unusual work load. This can have several impacts, especially overwhelming systems used as data input and output providers (DB, brokers, …), and this can end up in messages lost because of processing errors.&lt;/p&gt;

&lt;p&gt;Spark now ships back pressure mechanisms (on both sides), and you can also use &lt;code&gt;spark.streaming.receiver.maxRate&lt;/code&gt; that will define the maximum number of records per second a batch will process. This is extremely useful in case of recovery or during application upgrade, to avoid the firehose effect of letting messages queued in a broker.&lt;/p&gt;

&lt;h3 id=&quot;life-cycle&quot;&gt;Life cycle&lt;/h3&gt;

&lt;p&gt;If you have run stateful operations, or want complete recovery of a failed driver with no data loss, &lt;strong&gt;checkpointing&lt;/strong&gt; is mandatory.
Both last data received and jobs meta data are checkpointed. This means that if you modify code job and redeploy, you also need to remove checkpoint directory. Even if you modify application submission configuration (number of cores, memory to allocate, …) you’ll have to do so.&lt;/p&gt;

&lt;p&gt;Don’t forget to enable &lt;strong&gt;graceful shutdown&lt;/strong&gt;. When enabled, a hook is added to the shutdown sequence so the driver won’t stop until current batch is fully finished, while receiver has stopped and has no pending messages to be processed.&lt;/p&gt;

&lt;p&gt;This was previously done with following piece of code&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ShutdownHookThread&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But since 1.4 you can also use the following property&lt;/p&gt;

&lt;div class=&quot;language-properties highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;py&quot;&gt;spark.streaming.stopGracefullyOnShutdown&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;true&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;tuning&quot;&gt;Tuning&lt;/h3&gt;

&lt;p&gt;Apart from obvious or mandatory &lt;a href=&quot;http://spark.apache.org/docs/latest/configuration.html&quot;&gt;parameters&lt;/a&gt;, there are several important things to tune up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;configuring &lt;strong&gt;block interval&lt;/strong&gt; (default is 200ms) improves performances a lot (divided batch processing time by 4 for us). Basically, for a small cluster and small amount of data, there is no need to divide incoming data into blocks of 200ms. It’s better to form bigger blocks and avoid wasting time in sending and processing small ones. 
See &lt;a href=&quot;http://spark.apache.org/docs/latest/streaming-programming-guide.html#level-of-parallelism-in-data-receiving&quot;&gt;Spark performance tuning&lt;/a&gt; for details.&lt;/li&gt;
  &lt;li&gt;number of &lt;strong&gt;concurrent jobs&lt;/strong&gt; is also important to setup if you have more than one output operation in your driver. If you don’t raise this number, each output operation will be run sequentially. The drawback is that it will be harder to detect jobs that run longer than the configured batch time, as operations will continue to run while a new batch is getting processed.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;don’t use the default serializer&lt;/strong&gt;: it’s a well-known fact, Java serialization isn’t efficient. Spark supports Kryo, but that requires to write read and write functions.&lt;/li&gt;
  &lt;li&gt;configure &lt;strong&gt;cleaner TTL&lt;/strong&gt;, or RDD will be kept in memory forever.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here is a sample driver submission script&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/root/spark'&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SPARK_MASTER&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'spark://host:6066'&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$SPARK_HOME&lt;/span&gt;/bin/spark-submit &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --class com.foobot.stream.DatapointStream &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --master &lt;span class=&quot;nv&quot;&gt;$SPARK_MASTER&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --deploy-mode cluster &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --supervise &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --executor-memory 1536m &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --total-executor-cores 6 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --driver-memory 1G &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --driver-java-options &lt;span class=&quot;s2&quot;&gt;&quot;-XX:MaxPermSize=512m&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.streaming.blockInterval&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;500 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.streaming.concurrentJobs&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;6 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.cleaner.ttl&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1800 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.executor.logs.rolling.strategy&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.executor.logs.rolling.time.interval&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;daily &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.executor.logs.rolling.maxRetainedFiles&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;10 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 --conf spark.streaming.receiver.maxRate&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;30 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 /home/ec2-user/spark-drivers/spark-driver-datapoint.jar &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
 &lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;What we shared here is experience using Spark Streaming, from prototyping to production, with a particular focus on how to get the best of it without wasting too much resources. 
Most of these thoughts and advice remain valid for bigger clusters and workloads, but there would be different approaches and topics to discuss.&lt;/p&gt;

</description>
        <pubDate>Tue, 21 Jun 2016 10:00:00 +0200</pubDate>
        <link>http://0.0.0.0:4000/spark/streaming/cluster/ec2/aws/lean/2016/06/21/lean-spark-streaming.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/spark/streaming/cluster/ec2/aws/lean/2016/06/21/lean-spark-streaming.html</guid>
        
        
        <category>spark</category>
        
        <category>streaming</category>
        
        <category>cluster</category>
        
        <category>ec2</category>
        
        <category>aws</category>
        
        <category>lean</category>
        
      </item>
    
      <item>
        <title>Detecting and visualizing Foobot communities with Louvain method, Spark GraphX and D3.js</title>
        <description>&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;

&lt;p&gt;Here at Airboxlab, we collect and analyze indoor pollution to make people life safer and easier.&lt;/p&gt;

&lt;p&gt;We’re analyzing &lt;a href=&quot;https://foobot.io&quot;&gt;Foobot&lt;/a&gt; sensors data individually so we can inform and alert our customers when pollution levels are higher than recommended, but we’re also trying to analyze global trends with various technics.&lt;/p&gt;

&lt;p&gt;Lately, we’ve been interested in using community detection algorithms. Our hopes are to analyze communities size and evolution over time, find trends, and correlate their appearance with external factors.&lt;/p&gt;

&lt;p&gt;These algorithms are known to be used by major social networks companies to detect communities in their networks. There are also lot of academic researches in this field; analyzing various types of data sets with community detection algorithms can help find how people are connected. For instance, analyzing phone call logs can highlight where money can be invested in new infrastructure, what are the main communities in a region or country and how they are composed (among criterion like language, age, …)&lt;/p&gt;

&lt;p&gt;There are different methods for community detection, like &lt;em&gt;Minimum-cut&lt;/em&gt;, &lt;em&gt;Hierarchical clustering&lt;/em&gt;, &lt;em&gt;Girvan-Newman algorithm&lt;/em&gt; or &lt;em&gt;Modularity maximization&lt;/em&gt;.
Introductions for these methods can be found on &lt;a href=&quot;https://en.wikipedia.org/wiki/Community_structure&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Discovering communities can also be seen as a clustering problem within graph structures.&lt;/p&gt;

&lt;h2 id=&quot;louvain-algorithm&quot;&gt;Louvain algorithm&lt;/h2&gt;

&lt;p&gt;Louvain method was originally described&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; by Vincent D. Blondel, Jean-Loup Guillaume, Renaud Lambiotte and Etienne Lefebvre. The algorithm took the name of the &lt;em&gt;Université catholique de Louvain&lt;/em&gt; in Belgium, where the 4 authors are researchers.&lt;/p&gt;

&lt;p&gt;It aims at maximizing modularity using heuristic.&lt;/p&gt;

&lt;h4 id=&quot;definition&quot;&gt;Definition&lt;/h4&gt;

&lt;p&gt;Modularity value to be optimized is defined as:
&lt;img src=&quot;https://upload.wikimedia.org/math/c/f/6/cf68353cacdbbaf0c5d53c251083af4b.png&quot; alt=&quot;mod&quot; title=&quot;Modularity formula&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/f/8/9/f896be3d8636bddc74beebe184293aff.png&quot; alt=&quot;Aij&quot; /&gt; is the weight of the edge between &lt;em&gt;i&lt;/em&gt; and &lt;em&gt;j&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/2/6/e/26e634477c7a1285bb21c5df84371894.png&quot; alt=&quot;ki&quot; /&gt; is the sum of the weights of the edges attached to &lt;em&gt;i&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/6/f/8/6f8f57715090da2632453988d9a1501b.png&quot; alt=&quot;m&quot; /&gt; is half the sum of all edge weights in the graph.&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/d/9/8/d9899588b2b28a768a63ade0f3523596.png&quot; alt=&quot;ci&quot; /&gt; is the community to which &lt;em&gt;i&lt;/em&gt; is attached&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;https://upload.wikimedia.org/math/f/1/0/f10f03c9836c36537d2539196058bfa2.png&quot; alt=&quot;delta&quot; title=&quot;delta&quot; /&gt; is 1 if &lt;img src=&quot;https://upload.wikimedia.org/math/d/9/8/d9899588b2b28a768a63ade0f3523596.png&quot; alt=&quot;ci&quot; /&gt; = &lt;img src=&quot;https://upload.wikimedia.org/math/e/b/e/ebeeb713d38e86da62ba72e61376a622.png&quot; alt=&quot;cj&quot; /&gt; (same community), 0 otherwise.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The algorithm has a 2 steps approach that are repeated iteratively until modularity value is optimized.&lt;/p&gt;

&lt;p&gt;First, the method looks for small communities by optimizing modularity locally. Second, it aggregates nodes belonging to the same community and builds a new network. Nodes of this network are the aggregated ones built during 2nd phase. It iterates until modularity value is optimized.&lt;/p&gt;

&lt;p&gt;A graphical representation of the iterations can be found in original paper&lt;sup id=&quot;fnref:1:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, and is reproduced below&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://0.0.0.0:4000assets/louvain/pol.jpg&quot; alt=&quot;iterations&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;pros&quot;&gt;Pros&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Scalability (performs faster on huge graphs than other methods)&lt;/li&gt;
  &lt;li&gt;Simple to code&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cons&quot;&gt;Cons&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Iterative process can hide small communities found during intermediate phases. The result may be a coarse-grained high level representation of communities, which may not have the granularity needed for analysis. Hopefully, the nature of the algorithm makes it simple to save intermediate phases’ results so we can analyze different communities structures at different levels&lt;/li&gt;
  &lt;li&gt;Heuristic used to initialize phases and find local maximums can lead to not reproducible and not always optimized results. But this is the same with all data algorithms relying on heuristic (K-Means&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; for instance)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;applications&quot;&gt;Applications&lt;/h4&gt;

&lt;p&gt;The original study was based on phone calls logs originated from Belgian telecommunication operators.&lt;/p&gt;

&lt;p&gt;Some public examples of applications can be found on &lt;a href=&quot;https://perso.uclouvain.be/vincent.blondel/research/louvain.html&quot;&gt;Vincent Blondel’s personal blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, here is a detailed study made on &lt;a href=&quot;http://arxiv.org/pdf/1502.03406.pdf&quot;&gt;mobile phone data sets&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;An implementation for Apache Spark is available on &lt;a href=&quot;https://github.com/Sotera/spark-distributed-louvain-modularity&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;finding-foobots-communities&quot;&gt;Finding Foobots communities&lt;/h2&gt;

&lt;p&gt;First of all, you may be asking: but how are Foobots connected to each other? Simple answer: they aren’t. There is no direct relation or link between 2 devices, except when they both have the same owner.&lt;/p&gt;

&lt;p&gt;As a consequence, we will draw artificial links (or edges) between them, based on following criteria:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;geographical distance&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; between devices&lt;/li&gt;
  &lt;li&gt;euclidean distance&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; between average pollutant values of devices&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Same thing for edges weights: as stated in modularity definition, weight of edges is taken into account and is playing a role in nodes (or vertices) grouping.&lt;/p&gt;

&lt;p&gt;Setting a meaningful weight on each edge is a tricky problem, and there are probably multiple solutions to it; it will highly depend on what we analyze, what we want to find or what we want to correlate to.&lt;/p&gt;

&lt;p&gt;For the purpose of this article, we choose to define weight by using the distance between pollutant values of devices: the closer values are, the bigger weight will be.&lt;/p&gt;

&lt;p&gt;Let’s start with fetching a Pair RDD that will have a key defined by the unique device identifier (UUID), and value being an array of the average sensor values (here taking only PM2.5&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;, although it would be interesting to include VOC&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; too), plus geolocation of device as a (latitude, longitude) tuple. For this article, we took a sample of connected devices, and the last 30 minutes of data for each.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loaded&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;, &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//some function that fetches data
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//(UUID, (Latitude, Longitude))
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoList&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;,&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;,&lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;...&lt;/span&gt;  

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now that we have our values, we will compute average and standard deviation for sensor values, and normalize them.
Note that normalization isn’t necessary here as our input array contains only PM values.
Definition of &lt;code&gt;Utils&lt;/code&gt; can be found on &lt;a href=&quot;https://github.com/airboxlab/Louvain_sample&quot;&gt;our github&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Utils._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;means&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stdevs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;meansAndStdevs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loaded&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sensorValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoloc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sensorValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stdevs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoloc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Then we define graph vertices, by associating each UUID with a unique long identifier (from &lt;code&gt;hashCode()&lt;/code&gt;). 
Long identifiers are required by Spark GraphX API.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalized&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sensorValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoloc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sensorValues&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoloc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hashCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertexIds&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now we definie edges. We artificially link Foobots by checking their geographical distance. 
We define edge weight as a function of euclidean distance between 2 devices average sensor values.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;RDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cartesian&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//no loop
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoDistance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;//geo distance must be &amp;lt; 10km
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;euclideanDistance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;And then, we generate the graph:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertexIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now that we have a graph, we can run Louvain algorithm on it. Our reference implementation can be found &lt;a href=&quot;https://github.com/Sotera/spark-distributed-louvain-modularity&quot;&gt;here&lt;/a&gt;.
We slightly modified it, mainly to keep stages data in memory so we don’t require HDFS.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;InMemoryLouvainRunner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;louvainGraph&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;VertexState&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;runner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Time for a little reverse mapping game: remember we mapped UUIDs with Long identifiers. We want to get UUIDs back.
We then map each vertex id in edges (source and destination) with their corresponding UUID.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resolvedVertices&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;louvainGraph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertexIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vxId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resolvedEdges&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;louvainGraph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dstId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertexIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vxSrcId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vxDstId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linkWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srcUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vxDstId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linkWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srcUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vertexIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vxDstId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linkWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;srcUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dstUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dstUuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linkWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is the final step: output the result as a JSON file that will be used later to plot our results in graphs.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;//Helper classes
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;communityId&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;polLevel&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsLink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsGraph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;JsNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;JsLink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//Transform vertices
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoNodes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;JsNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resolvedVertices&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geoList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strLat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLoc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strLat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaledWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nodeWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strLat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uuid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hashCode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strLon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoNode&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${geoNode._2} ${geoNode._3}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;geoNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distinct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//Transform edges
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonEdges&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;JsLink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;louvainGraph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsLink&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;srcId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dstId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaledWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//Output to file
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;writeValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/www/html/communities.json&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JsGraph&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geoNodes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonEdges&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;plotting-results-with-d3&quot;&gt;Plotting results with D3&lt;/h2&gt;

&lt;p&gt;Let’s plot our results to visualize more clearly size of communities and links between them. 
Here we use D3.js for the tons of features and graph types it provides, and first graph we plot is a Force directed graph (definition and other exemples &lt;a href=&quot;https://bl.ocks.org/mbostock/4062045&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;iframe src=&quot;/assets/louvain/simple_com.html&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; border=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;border-style: none;width: 100%; height: 680px;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This gives us a first overview of how communities were built, and how they are “linked”. Note that size of node is given by community weight, but this weight has been scaled (logarithmically) so it can fit on a map. So are much bigger than what is actually rendered.&lt;/p&gt;

&lt;p&gt;Finally, as we have kept geographical coordinates of communities (by assigning one of the Foobot’s to the community - could be more accurate by taking the one which has the smaller distance to every other), it is possible to plot a map, like below.&lt;/p&gt;

&lt;iframe src=&quot;/assets/louvain/geo.html?cx=-95&amp;amp;cy=34&amp;amp;s=680&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; border=&quot;0&quot; cellspacing=&quot;0&quot; style=&quot;border-style: none;width: 100%; height: 680px;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;em&gt;Notes&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data snapshot at 2016-02-09 4.PM GMT (11.AM EST / 8.AM PST)&lt;/li&gt;
  &lt;li&gt;You can find sources for these graphs in &lt;a href=&quot;https://github.com/airboxlab/Louvain_sample&quot;&gt;our github&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In this article we’ve seen an introduction on communities detection in graphs, especially with Louvain algorithm, and we’ve used Foobot dataset to compute and plot communities on a map. Deeper investigation could include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;try another algorithm, like &lt;a href=&quot;https://en.wikipedia.org/wiki/DBSCAN&quot;&gt;DBSCAN&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;find how communities come and go, analyze and predict appearance of population of users with bad air quality.&lt;/li&gt;
  &lt;li&gt;study correlation with external factors, like outdoor air quality.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/0803.0476&quot;&gt;Louvain method original paper&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:1:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/K-means_clustering&quot;&gt;K-Means&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Haversine_formula&quot;&gt;Haversine formula for geographical distance calculation&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Euclidean_distance&quot;&gt;Euclidean distance&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Particulates&quot;&gt;Particulates definition&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Volatile_organic_compound&quot;&gt;Volatile organic coumpounds definition&lt;/a&gt;&amp;nbsp;&lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 12 Feb 2016 00:00:00 +0100</pubDate>
        <link>http://0.0.0.0:4000/spark/graphx/machine-learning/d3/louvain/2016/02/12/louvain.html</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/spark/graphx/machine-learning/d3/louvain/2016/02/12/louvain.html</guid>
        
        
        <category>spark</category>
        
        <category>graphx</category>
        
        <category>machine-learning</category>
        
        <category>D3</category>
        
        <category>louvain</category>
        
      </item>
    
  </channel>
</rss>
